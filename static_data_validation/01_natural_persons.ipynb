{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82154ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import time\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file name and location\n",
    "current_date = time.strftime(\"%Y%m%d\")\n",
    "output_file = 'natural_persons_main' + current_date + '.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a175802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "file_path = '../data/report_2.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93041d80",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "# select only natural persons\n",
    "df_natural = df[df['Party Type']=='Natural Person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing party name\n",
    "df_natural.loc[:,'Party Name_pre']=df_natural['Party Name'].copy()\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str \\\n",
    "                                                           .lower() \\\n",
    "                                                           .replace(r'[^\\w\\s]',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepocessing 'Identification Document Number' remove space & casing\n",
    "df_natural.loc[:,'Identification Document Number_pre']=df_natural['Identification Document Number'].copy()\n",
    "df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str \\\n",
    "                                                                                                   .lower() \\\n",
    "                                                                                                   .replace(r'[^\\w\\s]',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c93a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create beneficiary only list\n",
    "bene_only = df_natural.groupby('Party ID')['Relationship (Party Role)'] \\\n",
    "                      .agg(set) \\\n",
    "                      .reset_index(name = 'role_set')\n",
    "\n",
    "bene_only = bene_only[bene_only['role_set'] == {'Beneficiary'}]\n",
    "bene_only_list = bene_only['Party ID'].to_list()\n",
    "\n",
    "df_natural['bene_only'] = df_natural['Party ID'].isin(bene_only_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "df_natural['Date of Birth']  = pd.to_datetime(df_natural['Date of Birth'], format='%Y-%m-%d', errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b411468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add universal columns\n",
    "df_natural['Batch'] = input(\"Year, Quarter: (eg. format: 2023 Q1)\")\n",
    "df_natural[['Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Acceptable Exception']] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3831a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9deaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np1: same name & dob but passport/id country != nationality\n",
    "# location: sheet 1\n",
    "tab1 = df_natural.copy()\n",
    "\n",
    "#create list of Party IDs with HK permanent ID\n",
    "HK_permID = tab1[tab1['Identification Document Type'] == 'HK Permanent ID']\n",
    "HK_permID = HK_permID.drop_duplicates(subset = ['Party ID'])\n",
    "HK_permID_list = HK_permID['Party ID'].tolist()\n",
    "\n",
    "#create list of British Overseas Territories Passports (obtained from google)\n",
    "Brit_set = {'Anguilla','Bermuda','Virgin Islands','Cayman Islands','Gibraltar','Guernsey','Jersey','Manx','Montserrat',\n",
    "            'Saint Helena','Turks and Calcos Islands','Isle Of Man'}\n",
    "\n",
    "# identification Document Type ==  'Passport'\n",
    "tab1 = tab1[tab1['Identification Document Type'] == 'Passport']\n",
    "\n",
    "#create group identifier: [key]\n",
    "tab1['key'] = tab1['Party Name_pre'].astype(str) + \\\n",
    "              tab1['Date of Birth'].astype(str)\n",
    "\n",
    "#Replace Brit Overseas Territories Passports with UK passports\n",
    "tab1_Brit = tab1.copy()\n",
    "tab1_Brit.loc[tab1['Identification Document Issue Country'].isin(Brit_set), \n",
    "              'Identification Document Issue Country'] = \"United Kingdom\"\n",
    "\n",
    "# create group identifier: [passport key]\n",
    "tab1['passport_key'] = tab1_Brit['Party Name_pre'].astype(str) + \\\n",
    "                       tab1_Brit['Date of Birth'].astype(str) + \\\n",
    "                       tab1_Brit['Identification Document Issue Country'].astype(str)\n",
    "\n",
    "# create group identifier: [nationality key]\n",
    "tab1['nationality_key'] = tab1['Party Name_pre'].astype(str) + \\\n",
    "                          tab1['Date of Birth'].astype(str) + \\\n",
    "                          tab1['Nationality'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "#create list of nationalities\n",
    "tab1_nationality_list = tab1.nationality_key.tolist()\n",
    "#check if passports can be found in list of nationalities, flag if cannot be found\n",
    "tab1['flag'] = ~(tab1['passport_key'].isin(tab1_nationality_list))\n",
    "\n",
    "#create list of passports\n",
    "tab1_pp_list = tab1.passport_key.tolist()\n",
    "#check if nationalities can be found in list of passports, flag if cannot be found\n",
    "tab1['flag2'] = ~(tab1['nationality_key'].isin(tab1_pp_list))\n",
    "\n",
    "#filter for records where passports cannot be found in nationalities and vice versa\n",
    "tab1_filter = tab1[(tab1['flag'] == True) | \n",
    "                   (tab1['flag2'] == True)]\n",
    "          \n",
    "#create list of parties to flag based on \"key\" [party name + DOB]\n",
    "tab1_filter_list = tab1_filter.key.tolist()\n",
    "\n",
    "#retrieve all records that is in list of parties to flag\n",
    "tab1_columns = tab1[(tab1['key'].isin(tab1_filter_list))]\n",
    "\n",
    "#indicate if party ID has HK Perm ID, if nationality- HK\n",
    "tab1_columns['HK Permanent ID?'] = \"\"\n",
    "tab1_columns.loc[((tab1_columns['Party ID'].isin(HK_permID_list)) & \n",
    "                  (tab1_columns['Nationality'] == \"Hong Kong\")),\n",
    "                 'HK Permanent ID?'] = 'True'\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab1_columns['Inconsistency'] = 'Same Name & DOB but Passport ID Doc Ctry <> Nationality'\n",
    "\n",
    "#drop duplicates\n",
    "tab1_columns = tab1_columns.drop_duplicates(subset = ['Party ID',\n",
    "                                                      'Identification Document Type',\n",
    "                                                      'Identification Document Issue Country',\n",
    "                                                      'Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np2: same name & dob but nationality != id proof (SG, Swiss, Italian, Germany, French, Liechtenstein)\n",
    "# location: sheet 1\n",
    "tab2 = df_natural.copy()\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab2['key'] = tab2['Party Name_pre'].astype(str) + \\\n",
    "              tab2['Date of Birth'].astype(str)\n",
    "\n",
    "# 2.1 checking for sg pink NRIC\n",
    "tab2_1 = tab2[tab2['Identification Document Type'] == 'SG Pink NRIC']\n",
    "\n",
    "# create a [Nationality] set for each group\n",
    "tab2_nationality = tab2_1.groupby('key')['Nationality'] \\\n",
    "                        .agg(set) \\\n",
    "                        .reset_index(name = 'nationality_set')\n",
    "\n",
    "nationality_set = tab2_nationality.nationality_set.tolist()\n",
    "\n",
    "# check if Singapore exist in [Nationality]\n",
    "def check_singapore(nationality_set): #check if Singapore exists in the set of Nationality\n",
    "    singapore_set = {'Singapore'}\n",
    "    result = nationality_set.difference(singapore_set)\n",
    "    if 'Singapore' in nationality_set: return 'correct'\n",
    "    else: return result\n",
    "    \n",
    "tab2_nationality['check_singapore'] = tab2_nationality['nationality_set'].apply(lambda x: check_singapore(x))\n",
    "tab2_1_error = tab2_nationality[tab2_nationality['check_singapore'] != 'correct']\n",
    "\n",
    "# 2.2 checking for national id of eu countries\n",
    "# select rows  with national id of eu countries\n",
    "nationality_list = ['Switzerland', 'Italy', 'Germany', 'France', 'Liechtenstein']\n",
    "tab2_2 = tab2[tab2['Identification Document Type'] == 'National ID']\n",
    "tab2_2_filter = tab2_2[(tab2_2['Identification Document Issue Country'].isin(nationality_list))]\n",
    "\n",
    "# create a [Nationality] set for each group\n",
    "tab2_2_nationality = tab2_2_filter.groupby('key')['Nationality'] \\\n",
    "                                  .agg(set) \\\n",
    "                                  .reset_index(name='nationality_set')\n",
    "\n",
    "tab2_nationality_set = tab2_2_nationality.nationality_set.tolist()\n",
    "\n",
    "# create a [Identification Document Issue Country] set for each group\n",
    "tab2_2_idctry = tab2_2_filter.groupby('key')['Identification Document Issue Country'] \\\n",
    "                             .agg(set) \\\n",
    "                             .reset_index(name='idctry_set')\n",
    "\n",
    "tab2_2_idctry['nationality_set'] = tab2_nationality_set\n",
    "\n",
    "# compare two sets: set(idcrty) - set(nationality)\n",
    "def compare_country_sets_reverse(idctry_set, nationality_set): #compare difference btw {ID doc ctry} and {nationality}\n",
    "    result = idctry_set.difference(nationality_set)\n",
    "    if result: return result #if result not empty, return result\n",
    "    else: return 'correct' #if result IS empty, return 'correct'\n",
    "\n",
    "# extract groups whose sets is not identical     \n",
    "tab2_2_idctry['set_diff'] = tab2_2_idctry.apply(lambda x:\n",
    "                                                compare_country_sets_reverse(x.idctry_set, x.nationality_set), \n",
    "                                                axis = 1)\n",
    "tab2_2_error = tab2_2_idctry[tab2_2_idctry['set_diff'] != 'correct']\n",
    "\n",
    "# v-lookup in originial df \n",
    "tab2_1_error_list = tab2_1_error['key'].tolist()\n",
    "tab2_2_error_list = tab2_2_error['key'].tolist()\n",
    "tab2_error_list = tab2_1_error_list + tab2_2_error_list\n",
    "\n",
    "tab2['exist'] = tab2['key'].isin(tab2_error_list)\n",
    "tab2_columns = tab2[tab2['exist'] == True]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab2_columns['Inconsistency'] = \\\n",
    "'Same Name & DOB but Nationality <> ID proof(SG, Swiss, Italian, Germany, French, Liechtenstein)'\n",
    "\n",
    "#drop duplicates\n",
    "tab2_columns = tab2_columns.drop_duplicates(subset=['Party ID','Identification Document Type',\n",
    "                                                    'Identification Document Issue Country','Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e173787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np4: same name & dob but diff place of birth\n",
    "# location: sheet 1\n",
    "tab4 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name & same DOB\n",
    "tab4['key'] = tab4['Party Name_pre'].astype(str) + \\\n",
    "              tab4['Date of Birth'].astype(str)\n",
    "\n",
    "# add a column to count no. of Place of Birth based on same Party Name & DOB\n",
    "tab4['unique_count'] = tab4.groupby(['key'])['Place of Birth'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Place of Birth \n",
    "tab4 = tab4[tab4['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab4_columns = tab4.drop_duplicates(['Party ID','key','Place of Birth'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab4_columns['Inconsistency'] = 'Same Name, DOB, Diff Place of Birth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0853295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np5: same name & dob & address type but diff address country\n",
    "# location: sheet 1\n",
    "tab5 = df_natural.copy()\n",
    "\n",
    "tab5 = tab5[tab5['Address Type'] == 'Existing Residential Address']\n",
    "\n",
    "# create concat column of same party name, DOB\n",
    "tab5['key'] = tab5['Party Name_pre'].astype(str) + tab5['Date of Birth'].astype(str)\n",
    "\n",
    "# add a column to count no. of Address - Country based on same Party Name & DOB\n",
    "tab5['unique_count'] = tab5.groupby(['key'])['Address - Country'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Address - Country \n",
    "tab5 = tab5[tab5['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab5_columns = tab5.drop_duplicates(subset=['Party ID','key','Address - Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab5_columns['Inconsistency'] = 'Same Name, DOB, Diff Address Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np6: same name & dob & id# but diff id doc type\n",
    "# location: sheet 1\n",
    "tab6 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab6['key'] = tab6['Party Name_pre'].astype(str) + \\\n",
    "              tab6['Date of Birth'].astype(str) + \\\n",
    "              tab6['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Type based on same party name, DOB & Identification Document Number\n",
    "tab6['unique_count'] = tab6.groupby(['key'])['Identification Document Type'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Type \n",
    "tab6 = tab6[tab6['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab6_columns = tab6.drop_duplicates(subset=['Party ID','key','Identification Document Type'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab6_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Doc Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np7: same name & dob & id# but diff id expiry\n",
    "# location: sheet 1\n",
    "tab7 = df_natural.copy()\n",
    "\n",
    "#Treat ID Document Expiry Date as a string\n",
    "tab7['Identification Document Expiry Date_1'] = tab7['Identification Document Expiry Date'].astype(str)\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab7['key'] = tab7['Party Name_pre'].astype(str) + \\\n",
    "              tab7['Date of Birth'].astype(str) + \\\n",
    "              tab7['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Expiry Date based on same party name, DOB & Identification Document Number\n",
    "tab7['unique_count'] = tab7.groupby(['key'])['Identification Document Expiry Date_1'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Expiry Date \n",
    "tab7 = tab7[tab7['unique_count'] > 1]\n",
    "\n",
    "#groupby party name/DOB/ID and party RM (RM UID.1)\n",
    "tab7['unique_count_party'] = tab7.groupby(['key'])['RM UID.1'] \\\n",
    "                                 .transform('nunique')\n",
    "\n",
    "tab7_exclude = tab7[(tab7['unique_count_party'] > 1) & \n",
    "                    (tab7['Identification Document Type'] == 'Declaration of Nationality')]\n",
    "\n",
    "#drop rows to be excluded\n",
    "tab7 = tab7.drop(tab7_exclude.index)\n",
    "\n",
    "# remove duplicates\n",
    "tab7_columns = tab7.drop_duplicates(subset = ['Party ID','key','Identification Document Expiry Date_1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab7_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Expiry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np8: same name & dob & id# but diff id country\n",
    "# location: sheet 1\n",
    "tab8 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab8['key'] = tab6['Party Name_pre'].astype(str) + \\\n",
    "              tab8['Date of Birth'].astype(str) + \\\n",
    "              tab8['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Issue Country based on same party name, DOB & Identification Document Number\n",
    "tab8['unique_count'] = tab8.groupby(['key'])['Identification Document Issue Country'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Issue Country \n",
    "tab8 = tab8[tab8['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab8_columns = tab8.drop_duplicates(subset=['key','Identification Document Issue Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab8_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Doc Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np9: same name & dob & id# but diff id issue date\n",
    "# location: sheet 1\n",
    "tab9 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab9['key'] = tab9['Party Name_pre'].astype(str) + \\\n",
    "              tab9['Date of Birth'].astype(str) + \\\n",
    "              tab9['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "#Treat ID date of issue as a string\n",
    "tab9['Identification Date of Issue_1'] = tab9['Identification Date of Issue'].astype(str)\n",
    "\n",
    "\n",
    "# add a column to count no. of Identification Date of Issue based on same party name, DOB & Identification Document Number\n",
    "tab9['unique_count'] = tab9.groupby(['key'])['Identification Date of Issue_1'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Date of Issue \n",
    "tab9 = tab9[tab9['unique_count'] > 1]\n",
    "\n",
    "#groupby party name/DOB/ID and party RM (RM UID.1)\n",
    "tab9['unique_count_party'] = tab9.groupby(['key'])['RM UID.1'] \\\n",
    "                                 .transform('nunique')\n",
    "\n",
    "tab9_exclude = tab9[(tab9['unique_count_party'] > 1) & \n",
    "                    (tab9['Identification Document Type'] == 'Declaration of Nationality')]\n",
    "\n",
    "#drop rows\n",
    "tab9 = tab9.drop(tab9_exclude.index)\n",
    "\n",
    "# remove duplicates\n",
    "tab9_columns = tab9.drop_duplicates(subset = ['key','Identification Date of Issue_1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab9_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Issue date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d48048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np10: same name & dob & id type & id coountry but diff id#\n",
    "# location: sheet 1\n",
    "tab10 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Type, Identification Document Issue Country \n",
    "tab10['key'] = tab10['Party Name_pre'].astype(str) + \\\n",
    "               tab10['Date of Birth'].astype(str) + \\\n",
    "               tab10['Identification Document Type'].astype(str) + \\\n",
    "               tab10['Identification Document Issue Country'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Number based on same party name, DOB, Identification Document Type,Identification Document Issue Country\n",
    "tab10['unique_count'] = tab10.groupby(['key'])['Identification Document Number_pre'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Number \n",
    "tab10 = tab10[tab10['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab10_columns = tab10.drop_duplicates(subset = ['Party ID','key','Identification Document Number_pre'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab10_columns['Inconsistency'] = 'Same Name, DOB, ID Doc Type, ID Doc Country, Diff ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np11: same name & dob & party rm but diff party id\n",
    "# location: sheet 1\n",
    "tab11 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Party RM\n",
    "tab11['key'] = tab11['Party Name_pre'].astype(str) + \\\n",
    "               tab11['Date of Birth'].astype(str) + \\\n",
    "               tab11['RM Name.1'].astype(str)\n",
    "\n",
    "# add a column to count no. of Party ID based on same party name, DOB & Party RM\n",
    "tab11['unique_count'] = tab11.groupby(['key'])['Party ID'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Party ID \n",
    "tab11 = tab11[tab11['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab11_columns = tab11.drop_duplicates(subset = ['key','Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab11_columns['Inconsistency'] = 'Same Name, DOB, Party RM, Diff Party ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214887e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np11A: aame name & same id type & id# but diff dob (Sheet 1)\n",
    "# location: sheet 1\n",
    "tab11a = df_natural.copy()\n",
    "\n",
    "#Treat DOB as a string\n",
    "tab11a['Date of Birth_1'] = tab11a['Date of Birth'].astype(str)\n",
    "\n",
    "# create concat column of same party name, DOB, Party RM\n",
    "tab11a['key'] = tab11a['Party Name_pre'].astype(str) + \\\n",
    "                tab11a['Identification Document Type'].astype(str) + \\\n",
    "                tab11a['Identification Document Number'].astype(str)\n",
    "\n",
    "# add a column to count no. of Party ID based on same party name, DOB & Party RM\n",
    "tab11a['unique_count'] = tab11a.groupby(['key'])['Date of Birth_1'] \\\n",
    "                               .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Party ID \n",
    "tab11a = tab11a[tab11a['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab11a_columns = tab11a.drop_duplicates(subset = ['key','Date of Birth'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab11a_columns['Inconsistency'] = 'Same Name, Same ID Doc Type, ID #, Diff DoB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S12: Same ID Doc Type, ID #, ID Doc Country, Diff Name (Sheet 2)\n",
    "tab12 = df_natural.copy()\n",
    "\n",
    "# Check if Identification Document Number contains invalid value\n",
    "tab12['invalid_identification_document_number'] = tab12['Identification Document Number'].isin(['[]','()', np.nan,'NA', \n",
    "                                                                                                'NA in iCare', \n",
    "                                                                                                'N.A In Icare', \n",
    "                                                                                                'n/a','na','N/A','N.A.',\n",
    "                                                                                                'N.A','indeterminata',\n",
    "                                                                                                'Indeterminata',' ','','.',\n",
    "                                                                                                '-','0','0000000','000000',\n",
    "                                                                                                'not available', \n",
    "                                                                                                'not applicable', \n",
    "                                                                                                'NIL', 'xx', 'not','XX', \n",
    "                                                                                                'Not available',\n",
    "                                                                                                '[Not Available]',\n",
    "                                                                                                '[Un Specified]'])\n",
    "\n",
    "\n",
    "#Filter for records where ID Doc Type / ID# / ID Doc Country is not blank or invalid\n",
    "tab12 = tab12[(tab12['Identification Document Type'] != \"\") & \n",
    "              (tab12['invalid_identification_document_number'] == False) &\n",
    "              (tab12['Identification Document Issue Country'] != \"\")]\n",
    "\n",
    "# create concat column\n",
    "tab12['key'] = tab12['Identification Document Type'].astype(str) + \\\n",
    "               tab12['Identification Document Issue Country'].astype(str) + \\\n",
    "               tab12['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of party name\n",
    "tab12['unique_count'] = tab12.groupby(['key'])['Party Name_pre'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 name\n",
    "tab12 = tab12[tab12['unique_count'] > 1]\n",
    "\n",
    "# drop duplicates\n",
    "#tab12 = tab12.sort_values(by=['Party Name_pre'])\n",
    "tab12_columns = tab12.drop_duplicates(subset = ['Party ID','key','Party Name_pre'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab12_columns['Inconsistency'] = 'Same ID Doc Type, ID #, ID Doc Country, Diff Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d946d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S13: DON expiry – issue date != 2 years or missing (Sheet 3)\n",
    "tab13 = df_natural.copy()\n",
    "\n",
    "# filter for Identification Document Type == Declaration of Nationality\n",
    "tab13 = tab13[tab13['Identification Document Type'] == 'Declaration of Nationality']\n",
    "\n",
    "# calculate time delta between Identification Document Expiry Date & Identification Document Expiry Date\n",
    "tab13['days_diff'] = tab13['Identification Document Expiry Date'] - tab13['Identification Date of Issue']\n",
    "\n",
    "# filter for days_diff > 731\n",
    "tab13_columns = tab13[(tab13['days_diff'] > dt.timedelta(731)) | \n",
    "                      (tab13['days_diff'].isna())]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab13_columns['Inconsistency'] = 'DON expiry – issue date != 2 years or missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975eae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S14: Invalid Place of Birth (Sheet 3)\n",
    "tab14 = df_natural.copy()\n",
    "\n",
    "# extract rows which Place of Birth contains invalid value\n",
    "tab14['invalid_place_of_birth'] = tab14['Place of Birth'].isin(['[]','()', np.nan,'NA', 'NA in iCare', 'N.A In Icare', \n",
    "                                                                'n/a','na','N/A','N.A.','N.A','indeterminata',\n",
    "                                                                'Indeterminata',' ','','.','-','0','0000000',\n",
    "                                                                '000000','not available', 'not applicable', \n",
    "                                                                'NIL', 'xx', 'not','XX', 'Not available','[Not Available]',\n",
    "                                                                '[Un Specified]'])\n",
    "tab14_filter = tab14[tab14['invalid_place_of_birth'] == True]\n",
    "\n",
    "tab14_columns = tab14_filter.drop_duplicates(subset = ['Party ID'])\n",
    "\n",
    "tab14_columns['Inconsistency'] = 'Invalid Place of Birth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S15: Invalid ID Doc Number (Sheet 3)\n",
    "tab15 = df_natural.copy()\n",
    "\n",
    "# extract rows which Identification Document Number contains invalid value\n",
    "tab15['invalid_identification_document_number'] = tab15['Identification Document Number'].isin(['[]','()', np.nan,'NA', \n",
    "                                                                                                'NA in iCare', \n",
    "                                                                                                'N.A In Icare', \n",
    "                                                                                                'n/a','na','N/A','N.A.',\n",
    "                                                                                                'N.A','indeterminata',\n",
    "                                                                                                'Indeterminata',' ','','.',\n",
    "                                                                                                '-','0','0000000','000000',\n",
    "                                                                                                'not available', \n",
    "                                                                                                'not applicable', \n",
    "                                                                                                'NIL', 'xx', 'not','XX', \n",
    "                                                                                                'Not available',\n",
    "                                                                                                '[Not Available]',\n",
    "                                                                                                '[Un Specified]'])\n",
    "tab15_filter = tab15[(tab15['invalid_identification_document_number'] == True) &\n",
    "                     (tab15['Identification Document Type']!='Declaration of Nationality')]\n",
    "\n",
    "tab15_columns = tab15_filter.drop_duplicates(subset = ['Party ID',\n",
    "                                                       'Identification Document Type',\n",
    "                                                       'Identification Document Issue Country',\n",
    "                                                       'Identification Document Number'])\n",
    "\n",
    "tab15_columns['Inconsistency'] = 'Invalid ID Doc #'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S16: ID Doc Issue Country is blank when ID doc type is not blank (Sheet 3)\n",
    "tab16 = df_natural.copy()\n",
    "\n",
    "tab16_filter = tab16[~tab16['Identification Document Type'].isna()]\n",
    "\n",
    "tab16_filter_2 = tab16_filter[tab16_filter['Identification Document Issue Country'].isna()]\n",
    "\n",
    "tab16_columns = tab16_filter_2.drop_duplicates(subset = ['Party ID',\n",
    "                                                         'Identification Document Type',\n",
    "                                                         'Identification Document Issue Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab16_columns['Inconsistency'] = 'ID Doc Issue Country is blank when ID doc type is not blank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a191b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S17: Party ID tagged to 2 portfolio RMs (Party Role = AH & BO only) (Sheet 3)\n",
    "tab17 = df_natural.copy()\n",
    "\n",
    "tab17_filter = tab17[(tab17['Relationship (Party Role)'] == 'Account Holder') |\n",
    "                     (tab17['Relationship (Party Role)'] == 'Beneficial Owner')]\n",
    "\n",
    "# add a column to count no. of party name\n",
    "tab17_filter['unique_count'] = tab17_filter.groupby(['Party ID'])['RM UID'] \\\n",
    "                                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Type \n",
    "tab17_filter = tab17_filter[tab17_filter['unique_count'] > 1]\n",
    "\n",
    "#drop duplicates\n",
    "tab17_columns = tab17_filter.drop_duplicates(subset = ['Party ID','RM UID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab17_columns['Inconsistency'] = 'Party ID tagged to 2 portfolio RMs (Party Role = AH & BO only)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66416c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S18: Party ID tagged to multiple Party RMs (Sheet 3)\n",
    "tab18 = df_natural.copy()\n",
    "\n",
    "tab18['unique_count'] = tab18.groupby(['Party ID'])['RM UID.1'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "tab18 = tab18[tab18['unique_count'] > 1]\n",
    "\n",
    "tab18 = tab18.sort_values(by = ['Party Name_pre'])\n",
    "\n",
    "tab18_columns = tab18.drop_duplicates(subset = ['Party ID','RM UID.1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab18_columns['Inconsistency'] = 'Party ID tagged to multiple Party RMs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S21: ID only and not from acceptable countries (Sheet 1)\n",
    "tab21 = df_natural.copy()\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab21['key'] = tab21['Party Name_pre'].astype(str) + tab21['Date of Birth'].astype(str)\n",
    "\n",
    "# count of ID doc type based on same name and DOB\n",
    "tab21['unique_count'] = tab21.groupby(['key'])['Identification Document Type'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres only 1 ID doc type and the ID doc type is ID/NRIC\n",
    "tab21_1 = tab21[(tab21['unique_count'] == 1) & (tab21['Identification Document Type'] == 'SG Pink NRIC')]\n",
    "tab21_2 = tab21[(tab21['unique_count'] == 1) & (tab21['Identification Document Type'] == 'National ID')]\n",
    "\n",
    "# Check if Nationality = Singaporean\n",
    "tab21_1_error = tab21_1[tab21_1['Nationality'] != 'Singapore']\n",
    "\n",
    "# Check if Nationality = acceptable countries\n",
    "country_list = ['Switzerland', 'Italy', 'Germany', 'France', 'Princip.Liechtenstein', 'Thailand', 'Singapore']\n",
    "tab21_2_error = tab21_2[~tab21_2['Nationality'].isin(country_list)]\n",
    "\n",
    "# v-lookup in originial df \n",
    "tab21_1_error_list = tab21_1_error['key'].tolist()\n",
    "tab21_2_error_list = tab21_2_error['key'].tolist()\n",
    "tab21_error_list = tab21_1_error_list + tab21_2_error_list\n",
    "\n",
    "tab21['exist'] = tab21['key'].isin(tab21_error_list)\n",
    "tab21_columns = tab21[tab21['exist'] == True]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab21_columns['Inconsistency'] = 'ID only and not from acceptable countries'\n",
    "\n",
    "#drop duplicates\n",
    "tab21_columns = tab21_columns.drop_duplicates(subset = ['Party ID', 'Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S22: Blue NRIC not SG Resident (Sheet 1)\n",
    "tab22 = df_natural.copy()\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab22['key'] = tab22['Party Name_pre'].astype(str) + tab22['Date of Birth'].astype(str)\n",
    "\n",
    "# count of ID doc type based on same name and DOB\n",
    "tab22['unique_count'] = tab22.groupby(['key'])['Identification Document Type'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres only 1 ID doc type and the ID doc type is Blue NRIC\n",
    "tab22 = tab22[(tab22['unique_count'] == 1) & \n",
    "              (tab22['Identification Document Type'] == 'SG Blue NRIC')]\n",
    "\n",
    "# Residential Pass Holder of = Singapore\n",
    "# Address type = Existing Residential Address \n",
    "# Address - Country = Singapore\n",
    "tab22_columns = tab22[~((tab22[\"Resident pass holder of\"] == 'Singapore') &\n",
    "                        (tab22[\"Address Type\"] == 'Existing Residential Address') &\n",
    "                        (tab22[\"Address - Country\"] == 'Singapore')\n",
    "                       )\n",
    "                     ]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab22_columns['Inconsistency'] = 'Blue NRIC not SG Resident'\n",
    "\n",
    "#drop duplicates\n",
    "tab22_columns = tab22_columns.drop_duplicates(subset = ['Party ID', 'Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dce9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S23: Invalid override expiry reason (Sheet 5)\n",
    "tab23 = df_natural.copy()\n",
    "\n",
    "#create group identifier: [key]\n",
    "tab23['key']=tab23['Party Name_pre'].astype(str) + tab23['Date of Birth'].astype(str)\n",
    "\n",
    "doc_types = ['SG Pink NRIC', 'National ID', 'Passport']\n",
    "tab23 = tab23[tab23[\"Identification Document Type\"].isin(doc_types)]\n",
    "\n",
    "tab23 = tab23[(tab23['Override Expiry'] == 'Yes') & \n",
    "              (tab23['Override Expiry Reason'] != 'Deceased')]\n",
    "\n",
    "tab23_columns = tab23.drop_duplicates(subset = ['Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab23_columns['Inconsistency'] = 'Invalid override expiry reason'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d27b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP S24: Override and deceased flag mismatch\n",
    "#S24: override reason and deceased flag mismatch\n",
    "#override=yes AND reason=deceased AND flag!=deceased\n",
    "#override=yes AND reason!=deceased AND flag=deceased\n",
    "#(override=no AND reason!=blank) OR (override=no AND flag=deceased)\n",
    "#try to combine if possible\n",
    "tab24 = df_natural.copy()\n",
    "\n",
    "#create group identifier: [key]\n",
    "tab24['key']=tab24['Party Name_pre'].astype(str) + tab24['Date of Birth'].astype(str)\n",
    "\n",
    "doc_types = ['SG Pink NRIC', 'National ID', 'Passport']\n",
    "tab24 = tab24[tab24[\"Identification Document Type\"].isin(doc_types)]\n",
    "\n",
    "tab24 = tab24[(cond1) |\n",
    "              (cond2)]\n",
    "\n",
    "tab24_columns = tab24.drop_duplicates(subset = ['Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab24_columns['Inconsistency'] = 'Override and Deceased Flag Mismatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c7f12",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 1\n",
    "df_1 = [tab1_columns,tab2_columns,tab4_columns,tab5_columns,tab6_columns,tab7_columns,tab8_columns,tab9_columns,\n",
    "        tab10_columns,tab11_columns,tab11a_columns,tab21_columns, tab22_columns]\n",
    "\n",
    "result_1 = pd.concat(df_1, join='outer', axis=0)\n",
    "result_1 = result_1.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_1['Beneficiary_role_only']=result_1['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_1 = result_1[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID','Party Name','RM UID.1','RM Name.1','Date of Birth','Place of Birth','Resident pass holder of',\n",
    "                    'Address Type','Address - Country','Nationality','Identification Document Type','Identification Document Issue Country',\n",
    "                    'Identification Document Number','Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Beneficiary_role_only','HK Permanent ID?']]\n",
    "\n",
    "#rename columns\n",
    "result_1.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID','Party Name','Party RM UID','Party RM Name','Date of Birth','Place of Birth','Resident pass holder of',\n",
    "                    'Address Type','Address - Country','Nationality','Identification Document Type','Identification Document Issue Country',\n",
    "                    'Identification Document Number','Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Beneficiary_role_only','HK Permanent ID?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e43d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 2\n",
    "result_2 = tab12_columns.sort_values(by=['key','Party Name_pre','Party ID'])\n",
    "result_2['Beneficiary_role_only']=result_2['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_2 = result_2[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID','Party Name','RM UID.1','RM Name.1','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Beneficiary_role_only']]\n",
    "# rename columns\n",
    "result_2.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID','Party Name','Party RM UID','Party RM Name','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Beneficiary_role_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 3\n",
    "df_3 = [tab13_columns,tab14_columns,tab15_columns,tab16_columns,tab17_columns,tab18_columns]\n",
    "\n",
    "result_3 = pd.concat(df_3, join='outer', axis=0)\n",
    "result_3 = result_3.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_3['Beneficiary_role_only']=result_3['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_3 = result_3 [['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID','Party Name','RM UID.1','RM Name.1','RM UID','RM Name','Date of Birth','Place of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date','Beneficiary_role_only']]\n",
    "\n",
    "# rename columns\n",
    "result_3.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID','Party Name','Party RM UID','Party RM Name','Portfolio RM UID','Portfolio RM Name','Date of Birth','Place of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date','Beneficiary_role_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ce454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 5\n",
    "df_5 = [tab23_columns,tab24_columns]\n",
    "\n",
    "result_5 = df_5\n",
    "result_5 = result_5.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_5['Beneficiary_role_only']=result_5['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_5 = result_5[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID', 'Party Name','RM UID.1','RM Name.1','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Number','Identification Document Issue Country',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Override Expiry','Override Expiry Reason','Override Expiry Justification',\n",
    "                    'Deceased Flag','Beneficiary_role_only']]\n",
    "\n",
    "# rename columns\n",
    "result_5.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                    'Party ID', 'Party Name','Party RM UID','Party RM Name','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Number','Identification Document Issue Country',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Override Expiry','Override Expiry Reason','Override Expiry Justification',\n",
    "                    'Deceased Flag','Beneficiary_role_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb543fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ExcelWriter(folder_to_save_files, mode='w',date_format = 'yyyy-mm-dd', \n",
    "                        datetime_format='yyyy-mm-dd')\n",
    "\n",
    "result_1.to_excel(writer, 'Same_name_diff_static_info', index=False) #tab1\n",
    "result_2.to_excel(writer, 'Same_ID_diff_name', index=False) #tab2\n",
    "result_3.to_excel(writer, 'incomplete_fields_or_2RM', index=False) #tab3\n",
    "result_5.to_excel(writer, 'Invalid_override_expiry', index=False) #tab5\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
