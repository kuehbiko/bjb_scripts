{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d313241",
   "metadata": {},
   "source": [
    "## Party Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c418640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file name and location\n",
    "current_date = time.strftime(\"%Y%m%d\")\n",
    "output_file = 'legal_entities_main_' + current_date + '.xlsx'\n",
    "output_file_text = 'natural_persons_main_' + current_date + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data source\n",
    "file_path = input(\"input file path of report 2: \") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd759a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text file for links used\n",
    "with open(output_file_text, 'w') as f:\n",
    "    f.write('Report path:' + file_path)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14a973",
   "metadata": {},
   "source": [
    "## For non-Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for individuals\n",
    "df_non_natural = df[df['Party Type']!='Natural Person']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1e78d",
   "metadata": {},
   "source": [
    "### Preprocessing of Party Name & Business Registration No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_natural.loc[:,'Party Name_pre']=df_non_natural['Party Name'].copy()\n",
    "\n",
    "df_non_natural['Party Name_pre'] = df_non_natural['Party Name_pre'].str.strip()\n",
    "df_non_natural['Party Name_pre'] = df_non_natural['Party Name_pre'].str.replace(\".\",\"\")\n",
    "df_non_natural['Party Name_pre'] = df_non_natural['Party Name_pre'].str.replace(\" \",\"\")\n",
    "df_non_natural['Party Name_pre'] = df_non_natural['Party Name_pre'].str.replace('\\t','')\n",
    "df_non_natural['Party Name_pre'] = df_non_natural['Party Name_pre'].str.replace(\",\",\"\")\n",
    "df_non_natural['Party Name_pre'] = df_non_natural['Party Name_pre'].str.lower()\n",
    "\n",
    "df_non_natural.loc[:,'Business Registration No_pre']=df_non_natural['Business Registration No'].copy()               \n",
    "df_non_natural['Business Registration No_pre'] = df_non_natural['Business Registration No_pre'].str.replace(\".\",\"\")\n",
    "df_non_natural['Business Registration No_pre'] = df_non_natural['Business Registration No_pre'].str.replace(\" \",\"\")\n",
    "df_non_natural['Business Registration No_pre'] = df_non_natural['Business Registration No_pre'].str.replace(\",\",\"\")\n",
    "df_non_natural['Business Registration No_pre'] = df_non_natural['Business Registration No_pre'].str.lower()\n",
    "\n",
    "# beneficiary only list\n",
    "bene_only = df_non_natural.groupby('Party ID')['Relationship (Party Role)'].agg(set).reset_index(name='role_set')\n",
    "bene_only = bene_only[bene_only['role_set']=={'Beneficiary'}]\n",
    "bene_only_list = bene_only['Party ID'].to_list()\n",
    "df_non_natural['bene_only'] = df_non_natural['Party ID'].isin(bene_only_list)\n",
    "\n",
    "#dates\n",
    "df_non_natural['Date of Incorporation']  = pd.to_datetime(df_non_natural['Date of Incorporation'], format='%Y-%m-%d', errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add universal columns\n",
    "df_non_natural['Batch'] = input(\"Year, Quarter: (eg. format: 2023 Q1)\")\n",
    "df_non_natural[['Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception']] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d1a6e",
   "metadata": {},
   "source": [
    "### Scenario1: Identify records with Same Party Name, Same Date of Incorporation, Same Party RM UID but different Party ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4738ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up rows that have duplicated party name, date of incorporation, and RM UID \n",
    "#tab1_dup = df_non_natural[df_non_natural.duplicated(['Party Name','Date of Incorporation','RM UID.1'])]\n",
    "\n",
    "tab1=df_non_natural.copy()\n",
    "#create concat column of same party name, same DOI & same Party RM (key)\n",
    "tab1['concat']=tab1['Party Name_pre'].astype(str) + tab1['Date of Incorporation'].astype(str) + tab1['RM UID.1'].astype(str)\n",
    "\n",
    "tab1_unique_partyID=tab1.copy()\n",
    "# Add a column to count no. of unique party IDs based on same Party Name, Party RM & DOI\n",
    "tab1_unique_partyID['Unique Party ID Count']=tab1_unique_partyID.groupby(['concat'])['Party ID'].transform('nunique')\n",
    "# Keep only rows where theres > 1 Party ID \n",
    "tab1_unique_partyID = tab1_unique_partyID[tab1_unique_partyID['Unique Party ID Count'] > 1]\n",
    "# remove duplicate Party IDs\n",
    "tab1_unique_partyID=tab1_unique_partyID.drop_duplicates(subset='Party ID')\n",
    "# Sort by Party Name\n",
    "tab1_test =tab1_unique_partyID.sort_values(by=['Party Name_pre'])\n",
    "#state inconsistency type in new column 'Inconsistency'\n",
    "tab1_test['Inconsistency'] = 'Same Name & DOI & RM, diff Party ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f7e39",
   "metadata": {},
   "source": [
    "### Scenario2: Relationship (Party Role) == “Account Holder” OR “Beneficial Owner”. Identify records with Same Party ID but different Portfolio RM UID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1879bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship (Party Role) == “Account Holder” OR “Beneficial Owner”\n",
    "tab2_fil = df_non_natural[(df_non_natural['Relationship (Party Role)']=='Account Holder')\n",
    "                         |(df_non_natural['Relationship (Party Role)']=='Beneficial Owner')]\n",
    "\n",
    "\n",
    "# remove duplicate Party IDs and Portfolio RM UIDs\n",
    "tab2_fil=tab2_fil.drop_duplicates(subset=['Party ID','RM UID'])\n",
    "\n",
    "# Add a column to count no. of portfolio RM UID based on same Party ID\n",
    "tab2_fil['Portfolio RM Count']=tab2_fil.groupby(['Party ID'])['RM UID'].transform('count')\n",
    "# Keep only rows where theres > 1 Party ID \n",
    "tab2_dup = tab2_fil[tab2_fil['Portfolio RM Count'] > 1]\n",
    "# Sort by Party Name\n",
    "tab2_test=tab2_dup.sort_values(by=['Party Name_pre'])\n",
    "\n",
    "tab2_test['Inconsistency'] = 'Party ID tagged to 2 portfolio RMs (Party Role = AH & BO only)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4007b",
   "metadata": {},
   "source": [
    "### Scenario4: Identify records with same Date of Incorporation, same Business Registration No, same Country of Incorporation, but different Party Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e654b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create concat column identifier of DOI,BizReg,COI\n",
    "tab4=df_non_natural.copy()\n",
    "\n",
    "#create concat column of same DOI, biz reg no & COI\n",
    "tab4['concat']=tab4['Date of Incorporation'].astype(str) + tab4['Business Registration No_pre'].astype(str) + tab4['Country of Incorporation'].astype(str)\n",
    "#create column to count no. of unique party names\n",
    "tab4['Unique party name count']=tab4.groupby(['concat'])['Party Name_pre'].transform('nunique')\n",
    "#keep rows where unique party name count is more than 1\n",
    "tab4=tab4[tab4['Unique party name count'] > 1]\n",
    "tab4 = tab4.sort_values(by=['concat','Unique party name count']) \n",
    "#remove duplicate Party IDs\n",
    "tab4_test=tab4.drop_duplicates(subset='Party ID')\n",
    "tab4_test['Inconsistency'] = 'Same DOI, Biz Reg No. & COI, diff Party Name'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04252fd1",
   "metadata": {},
   "source": [
    "### Scenario5: Identify records with Same Party Name, Date of Incorporation but different Country of Incorporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0475dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify records with same Same Party Name, Date of Incorporation\n",
    "tab5_dup = df_non_natural.copy()\n",
    "# create concat column identifier of Party name & DOI\n",
    "\n",
    "tab5_dup['concat']=tab5_dup['Party Name_pre'].astype(str) + tab5_dup['Date of Incorporation'].astype(str)\n",
    "\n",
    "# remove duplicate Party IDs\n",
    "tab5_dup=tab5_dup .drop_duplicates(subset='Party ID')\n",
    "\n",
    "# Add a column to count no. of unique COI based on same Party Name, & DOI\n",
    "tab5_dup['Unique COI Count']=tab5_dup.groupby(['Date of Incorporation','Party Name_pre'])['Country of Incorporation'].transform('nunique')\n",
    "\n",
    "tab5_test = tab5_dup[tab5_dup['Unique COI Count']>1]\n",
    "tab5_test['Inconsistency'] = 'Same Party Name & DOI, diff COI'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555efe1",
   "metadata": {},
   "source": [
    "### Scenario6: Identify records with Same Party Name, Country of Incorporation but different Date of Incorporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10708859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create concat column identifier of Party name & COI\n",
    "tab6=df_non_natural.copy()\n",
    "tab6['concat']=tab6['Party Name_pre'].astype(str) + tab6['Country of Incorporation'].astype(str)\n",
    "tab6['Date of Incorporation']=tab6['Date of Incorporation'].astype(str)\n",
    "tab6['Unique DOI Count']=tab6.groupby(['concat'])['Date of Incorporation'].transform('nunique')\n",
    "\n",
    "tab6_diff = tab6[tab6['Unique DOI Count']>1]\n",
    "tab6_test=tab6_diff.drop_duplicates(subset='Party ID')\n",
    "tab6_test['Inconsistency'] = 'Same Party Name & COI, diff DOI'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c0e96",
   "metadata": {},
   "source": [
    "### Scenario7: Identify records with  Address Type == Registered Business Address, Same Party Name, Date of Incorporation but different Address - Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for Address Type == Registered Business Address\n",
    "tab7_fil = df_non_natural[df_non_natural['Address Type']=='Registered Business Address']\n",
    "\n",
    "# create concat column identifier of Party name & DOI\n",
    "\n",
    "tab7_fil['concat']=tab7_fil['Party Name_pre'].astype(str) + tab7_fil['Date of Incorporation'].astype(str)\n",
    "tab7_fil['Unique Add Ctry Count']=tab7_fil.groupby(['concat'])['Address - Country'].transform('nunique')\n",
    "\n",
    "tab7_diff = tab7_fil[tab7_fil['Unique Add Ctry Count']>1]\n",
    "tab7_test =tab7_diff.drop_duplicates(subset='Party ID')\n",
    "tab7_test['Inconsistency'] = 'Same Name, DOI & Add Type, diff Add Ctry'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns for tab\n",
    "#tab7_test = tab7_diff[['Party ID', 'Party Name', 'RM UID.1','RM Name.1', 'Date of Incorporation', 'Country of Incorporation','Address Type','Address - Country','Business Registration No']] # extract certain columns\n",
    "#tab7_test.columns = ['Party ID', 'Party Name', 'Party RM UID','Party RM Name', 'Date of Incorporation', 'Country of Incorporation','Address Type','Address - Country','Business Registration No'] # rename columns\n",
    "\n",
    "# add in error type col\n",
    "#tab7_test['Inconsistency'] = 'Same Name, DOI & Add Type, diff Add Ctry'\n",
    "#tab7_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a2d1a",
   "metadata": {},
   "source": [
    "### Scenario8: Identify records with Same Party Name, Date of Incorporation but different Business Registration No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd99767",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab8_dup = df_non_natural.copy()\n",
    "# create concat column identifier of Party name & DOI\n",
    "\n",
    "tab8_dup['concat']=tab8_dup['Party Name_pre'].astype(str) + tab8_dup['Date of Incorporation'].astype(str)\n",
    "tab8_dup['Unique Biz Reg Count']=tab8_dup.groupby(['concat'])['Business Registration No_pre'].transform('nunique')\n",
    "\n",
    "tab8_diff = tab8_dup[tab8_dup['Unique Biz Reg Count']>1]\n",
    "tab8_diff =tab8_diff.drop_duplicates(subset='Party ID')\n",
    "tab8_test=tab8_diff.sort_values(by=['Party Name_pre'])\n",
    "\n",
    "tab8_test['Inconsistency'] = 'Same Name Same DOI, Diff Biz Reg No.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16715532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns for tab\n",
    "#tab8_test = tab8_diff[['Party ID', 'Party Name', 'RM UID.1','RM Name.1', 'Date of Incorporation', 'Country of Incorporation','Address Type','Address - Country','Business Registration No']] # extract certain columns\n",
    "#tab8_test.columns = ['Party ID', 'Party Name', 'Party RM UID','Party RM Name', 'Date of Incorporation', 'Country of Incorporation','Address Type','Address - Country','Business Registration No'] # rename columns\n",
    "\n",
    "# add in error type col\n",
    "#tab8_test['Inconsistency'] = 'Same Name Same DOI, Diff Biz Reg No.'\n",
    "#tab8_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a5c5e",
   "metadata": {},
   "source": [
    "### Scenario9: Invalid Biz Reg No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship (Party Role) not equals to “Beneficiary”\n",
    "tab9_fil = df_non_natural[df_non_natural['Relationship (Party Role)'] != 'Beneficiary']\n",
    "\n",
    "\n",
    "# extract rows which Business Registration No. contains invalid value\n",
    "#is there any way to regex this or do we need to add to the list manually\n",
    "tab9_fil['invalid_bizregno'] = tab9_fil['Business Registration No'].isin(['[]','()', np.nan, 'NA in iCare', 'N.A In Icare', 'n/a','na','N/A','N.A.','N.A','indeterminata','Indeterminata',' ','','.','-','0','0000000','000000','not available', 'not applicable', 'NIL', 'xx', 'not','XX', 'Not available'])\n",
    "tab9 = tab9_fil[tab9_fil['invalid_bizregno']==True]\n",
    "tab9_test =tab9.drop_duplicates(subset='Party ID')\n",
    "\n",
    "tab9_test['Inconsistency'] = 'Invalid Biz Reg No.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e2ae2",
   "metadata": {},
   "source": [
    "### Scenario10: Invalid Country of Incorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship (Party Role) not equals to “Beneficiary”\n",
    "tab10_fil = df_non_natural[df_non_natural['Relationship (Party Role)'] != 'Beneficiary']\n",
    "\n",
    "# extract rows which Country of incorp. contains invalid value\n",
    "#if its a dropdown, we can get a full list of countrys and do regex match\n",
    "#wont get new errors. all the errors are old legacy accounts\n",
    "tab10_fil['invalid_ctry'] = tab10_fil['Country of Incorporation'].isin(['[]','()', np.nan, 'NA in iCare', 'N.A In Icare', 'n/a','NA','N/A','N.A.','N.A','indeterminata','Indeterminata',' ','','.','-','0','0000000','000000','not available', 'not applicable', 'NIL', 'xx', 'not','XX', 'Not available', 'NBD/1717'])\n",
    "tab10_test = tab10_fil[tab10_fil['invalid_ctry']==True]\n",
    "#tab10_test = tab10[['Party ID', 'Relationship (Party Role)', 'Party Name', 'RM UID.1','RM Name.1', 'RM UID', 'RM Name', 'Business Registration No', 'Country of Incorporation','Address Type','Address - Country']]\n",
    "#tab10_test.columns = ['Party ID', 'Party Role', 'Party Name', 'Party RM UID','Party RM Name', 'Portfolio RM UID', 'Portfolio RM Name', 'Business Registration No', 'Country of Incorporation','Address Type','Address - Country']\n",
    "tab10_test['Inconsistency'] = 'Invalid Country of Incorp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5086f09b",
   "metadata": {},
   "source": [
    "### Scenario11: Invalid Address-Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decommission?? check. this may be a mandatory field\n",
    "# Relationship (Party Role) not equals to “Beneficiary”\n",
    "tab11_fil = df_non_natural[df_non_natural['Relationship (Party Role)'] != 'Beneficiary']\n",
    "\n",
    "# extract rows which Address Country contains invalid value\n",
    "#wont get new errors. all the errors are old legacy accounts\n",
    "tab11_fil['invalid_add'] = tab11_fil['Address - Country'].isin(['[]','()', np.nan, 'NA in iCare', 'N.A In Icare', 'n/a','NA','N/A','N.A.','N.A','indeterminata','Indeterminata',' ','','.','-','0','0000000','000000','not available', 'not applicable', 'NIL', 'xx', 'not','XX', 'Not available', 'NBD/1717'])\n",
    "tab11_test= tab11_fil[tab11_fil['invalid_add']==True]\n",
    "#tab11_test = tab11[['Party ID', 'Relationship (Party Role)', 'Party Name', 'RM UID.1','RM Name.1', 'RM UID', 'RM Name', 'Business Registration No', 'Country of Incorporation','Address Type','Address - Country']]\n",
    "#tab11_test.columns = ['Party ID', 'Party Role', 'Party Name', 'Party RM UID','Party RM Name', 'Portfolio RM UID', 'Portfolio RM Name', 'Business Registration No', 'Country of Incorporation','Address Type','Address - Country']\n",
    "tab11_test['Inconsistency'] = 'Invalid Address-Country'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c64a35",
   "metadata": {},
   "source": [
    "### Merge for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c3741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_1 = [tab1_test, tab5_test, tab6_test, tab7_test, tab8_test]\n",
    "df_2 = [tab2_test, tab9_test, tab10_test, tab11_test]\n",
    "\n",
    "# solution 1\n",
    "result_1 = pd.concat(df_1, join='outer', axis=0)\n",
    "result_1 = result_1.sort_values(by=['Party Name_pre', 'Inconsistency','Party ID'])\n",
    "#select columns for output\n",
    "result_1 = result_1[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                     'Valid Exception',\n",
    "                     'Party ID','Party Name','Party Type','RM UID.1','RM Name.1','Date of Incorporation',\n",
    "                     'Country of Incorporation','Address Type','Address - Country','Business Registration No',\n",
    "                     'bene_only']]\n",
    "#rename columns\n",
    "result_1.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                     'Valid Exception',\n",
    "                     'Party ID','Party Name','Party Type','Party RM UID','Party RM Name','Date of Incorporation',\n",
    "                     'Country of Incorporation','Address Type','Address - Country','Business Registration No',\n",
    "                     'bene_only']\n",
    "\n",
    "\n",
    "#display(result_1)\n",
    "\n",
    "# solution 2\n",
    "result_2 = pd.concat(df_2, join='outer', axis=0)\n",
    "result_2 = result_2.sort_values(by=['Party Name_pre', 'Inconsistency','Party ID'])\n",
    "result_2 = result_2[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                     'Valid Exception','Party ID', 'Relationship (Party Role)', 'Party Name', 'Party Type','RM UID.1','RM Name.1', \n",
    "                     'RM UID', 'RM Name', 'Business Registration No', 'Country of Incorporation','Address Type',\n",
    "                     'Address - Country','bene_only']]\n",
    "result_2.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                     'Valid Exception','Party ID', 'Party Role', 'Party Name','Party Type', 'Party RM UID','Party RM Name', \n",
    "                    'Portfolio RM UID', 'Portfolio RM Name', 'Business Registration No', 'Country of Incorporation',\n",
    "                    'Address Type','Address - Country','bene_only']\n",
    "\n",
    "\n",
    "\n",
    "# solution 3\n",
    "# extract columns for tab\n",
    "result_3 = tab4_test[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                     'Valid Exception','Party ID', 'Party Name', 'RM UID.1','RM Name.1', 'Date of Incorporation', \n",
    "                      'Business Registration No', 'Country of Incorporation',\n",
    "                      'bene_only']] # extract certain columns\n",
    "result_3.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date',\n",
    "                     'Valid Exception','Party ID', 'Party Name', 'Party RM UID','Party RM Name', 'Date of Incorporation', \n",
    "                    'Business Registration No', 'Country of Incorporation','bene_only'] # rename columns\n",
    "result_3 = result_3.sort_values(by=['Date of Incorporation', 'Country of Incorporation','Business Registration No',\n",
    "                                    'Inconsistency','Party ID'])\n",
    "#display(result_3)\n",
    "\n",
    "\n",
    "\n",
    "writer = ExcelWriter(output_file, mode='w')\n",
    "result_1.to_excel(writer, 'Same_name_diff_static_info', index=False) #tab1\n",
    "result_2.to_excel(writer, 'incomplete_fields_or_2RM', index=False) #tab2\n",
    "result_3.to_excel(writer, 'Same_details_diff_name', index=False) #tab3\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
