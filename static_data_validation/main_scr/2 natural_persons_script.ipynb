{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82154ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from pandas import ExcelWriter\n",
    "import time\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file name and location\n",
    "current_date = time.strftime(\"%Y%m%d\")\n",
    "output_file = 'natural_persons_main_' + current_date + '.xlsx'\n",
    "output_file_text = 'natural_persons_main_' + current_date + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a175802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data source\n",
    "file_path = input(\"input file path of report 2: \") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text file for links used\n",
    "with open(output_file_text, 'w') as f:\n",
    "    f.write('Report path: ' + file_path)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93041d80",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "# select only natural persons\n",
    "df_natural = df[df['Party Type']=='Natural Person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing of party name\n",
    "df_natural.loc[:,'Party Name_pre']=df_natural['Party Name'].copy()\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.strip()\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.replace(\".\",\"\")\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.replace(\" \",\"\")\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.replace('\\t','')\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.replace(\",\",\"\")\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36cbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepocessing 'Identification Document Number' to remove space & casing\n",
    "df_natural.loc[:,'Identification Document Number_pre']=df_natural['Identification Document Number'].copy()\n",
    "df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str.replace(\".\",\"\")\n",
    "df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str.replace(\" \",\"\")\n",
    "df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str.replace(\",\",\"\")\n",
    "df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "df_natural['Date of Birth']  = pd.to_datetime(df_natural['Date of Birth'], format='%Y-%m-%d', errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef52253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create beneficiary only list\n",
    "bene_only = df_natural.groupby('Party ID')['Relationship (Party Role)'] \\\n",
    "                      .agg(set) \\\n",
    "                      .reset_index(name = 'role_set')\n",
    "\n",
    "bene_only = bene_only[bene_only['role_set'] == {'Beneficiary'}]\n",
    "bene_only_list = bene_only['Party ID'].to_list()\n",
    "\n",
    "df_natural['bene_only'] = df_natural['Party ID'].isin(bene_only_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05072e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_natural['bene_only'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b411468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add universal columns\n",
    "df_natural['Batch'] = input(\"Year, Quarter: (eg. format: 2023 Q1)\")\n",
    "df_natural[['Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception']] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3831a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9deaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np1: same name & dob but passport/id country != nationality\n",
    "# location: sheet 1\n",
    "tab1 = df_natural.copy()\n",
    "tab1 = tab1[tab1['bene_only']==False]\n",
    "\n",
    "#create list of Party IDs with HK permanent ID\n",
    "HK_permID = tab1[tab1['Identification Document Type'] == 'HK Permanent ID']\n",
    "HK_permID = HK_permID.drop_duplicates(subset = ['Party ID'])\n",
    "HK_permID_list = HK_permID['Party ID'].tolist()\n",
    "\n",
    "#create list of British Overseas Territories Passports (obtained from google)\n",
    "Brit_set = {'Anguilla','Bermuda','Virgin Islands','Cayman Islands','Gibraltar','Guernsey','Jersey','Manx','Montserrat',\n",
    "            'Saint Helena','Turks and Calcos Islands','Isle Of Man'}\n",
    "\n",
    "# identification Document Type ==  'Passport'\n",
    "tab1 = tab1[tab1['Identification Document Type'] == 'Passport']\n",
    "\n",
    "#create group identifier: [key]\n",
    "tab1['key'] = tab1['Party Name_pre'].astype(str) + \\\n",
    "              tab1['Date of Birth'].astype(str)\n",
    "\n",
    "#Replace Brit Overseas Territories Passports with UK passports\n",
    "tab1_Brit = tab1.copy()\n",
    "'''\"\"\"tab1_Brit.loc[tab1['Identification Document Issue Country'].isin(Brit_set), \n",
    "              'Identification Document Issue Country'] = \"United Kingdom\"\"\"\"'''\n",
    "\n",
    "# create group identifier: [passport key]\n",
    "tab1['passport_key'] = tab1_Brit['Party Name_pre'].astype(str) + \\\n",
    "                       tab1_Brit['Date of Birth'].astype(str) + \\\n",
    "                       tab1_Brit['Identification Document Issue Country'].astype(str)\n",
    "\n",
    "# create group identifier: [nationality key]\n",
    "tab1['nationality_key'] = tab1['Party Name_pre'].astype(str) + \\\n",
    "                          tab1['Date of Birth'].astype(str) + \\\n",
    "                          tab1['Nationality'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "#create list of nationalities\n",
    "tab1_nationality_list = tab1.nationality_key.tolist()\n",
    "#check if passports can be found in list of nationalities, flag if cannot be found\n",
    "tab1['flag'] = ~(tab1['passport_key'].isin(tab1_nationality_list))\n",
    "\n",
    "#create list of passports\n",
    "tab1_pp_list = tab1.passport_key.tolist()\n",
    "#check if nationalities can be found in list of passports, flag if cannot be found\n",
    "tab1['flag2'] = ~(tab1['nationality_key'].isin(tab1_pp_list))\n",
    "\n",
    "#filter for records where passports cannot be found in nationalities and vice versa\n",
    "tab1_filter = tab1[(tab1['flag'] == True) | \n",
    "                   (tab1['flag2'] == True)]\n",
    "          \n",
    "#create list of parties to flag based on \"key\" [party name + DOB]\n",
    "tab1_filter_list = tab1_filter.key.tolist()\n",
    "\n",
    "#retrieve all records that is in list of parties to flag\n",
    "tab1_columns = tab1[(tab1['key'].isin(tab1_filter_list))]\n",
    "\n",
    "#indicate if party ID has HK Perm ID, if nationality- HK\n",
    "tab1_columns['HK Permanent ID?'] = \"\"\n",
    "tab1_columns.loc[((tab1_columns['Party ID'].isin(HK_permID_list)) & \n",
    "                  (tab1_columns['Nationality'] == \"Hong Kong\")),\n",
    "                 'HK Permanent ID?'] = 'True'\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab1_columns['Inconsistency'] = 'Same Name & DOB but Passport ID Doc Ctry <> Nationality'\n",
    "\n",
    "#drop duplicates\n",
    "tab1_columns = tab1_columns.drop_duplicates(subset = ['Party ID',\n",
    "                                                      'Identification Document Type',\n",
    "                                                      'Identification Document Issue Country',\n",
    "                                                      'Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np2: same name & dob but nationality != id proof (SG, Swiss, Italian, Germany, French, Liechtenstein, Thailand)\n",
    "# location: sheet 1\n",
    "tab2 = df_natural.copy()\n",
    "tab2 = tab2[tab2['bene_only']==False]\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab2['key'] = tab2['Party Name_pre'].astype(str) + \\\n",
    "              tab2['Date of Birth'].astype(str)\n",
    "\n",
    "# 2.1 checking for sg pink NRIC\n",
    "tab2_1 = tab2[tab2['Identification Document Type'] == 'SG Pink NRIC']\n",
    "\n",
    "# create a [Nationality] set for each group\n",
    "tab2_nationality = tab2_1.groupby('key')['Nationality'] \\\n",
    "                        .agg(set) \\\n",
    "                        .reset_index(name = 'nationality_set')\n",
    "\n",
    "nationality_set = tab2_nationality.nationality_set.tolist()\n",
    "\n",
    "# check if Singapore exist in [Nationality]\n",
    "def check_singapore(nationality_set): #check if Singapore exists in the set of Nationality\n",
    "    singapore_set = {'Singapore'}\n",
    "    result = nationality_set.difference(singapore_set)\n",
    "    if 'Singapore' in nationality_set: return 'correct'\n",
    "    else: return result\n",
    "    \n",
    "tab2_nationality['check_singapore'] = tab2_nationality['nationality_set'].apply(lambda x: check_singapore(x))\n",
    "tab2_1_error = tab2_nationality[tab2_nationality['check_singapore'] != 'correct']\n",
    "\n",
    "# 2.2 checking for national id of countries\n",
    "# select rows  with national id of countries\n",
    "nationality_list = ['Switzerland', 'Italy', 'Germany', 'France', 'Liechtenstein', 'Thailand']\n",
    "tab2_2 = tab2[tab2['Identification Document Type'] == 'National ID']\n",
    "tab2_2_filter = tab2_2[(tab2_2['Identification Document Issue Country'].isin(nationality_list))]\n",
    "\n",
    "# create a [Nationality] set for each group\n",
    "tab2_2_nationality = tab2_2_filter.groupby('key')['Nationality'] \\\n",
    "                                  .agg(set) \\\n",
    "                                  .reset_index(name='nationality_set')\n",
    "\n",
    "tab2_nationality_set = tab2_2_nationality.nationality_set.tolist()\n",
    "\n",
    "# create a [Identification Document Issue Country] set for each group\n",
    "tab2_2_idctry = tab2_2_filter.groupby('key')['Identification Document Issue Country'] \\\n",
    "                             .agg(set) \\\n",
    "                             .reset_index(name='idctry_set')\n",
    "\n",
    "tab2_2_idctry['nationality_set'] = tab2_nationality_set\n",
    "\n",
    "# compare two sets: set(idcrty) - set(nationality)\n",
    "def compare_country_sets_reverse(idctry_set, nationality_set): #compare difference btw {ID doc ctry} and {nationality}\n",
    "    result = idctry_set.difference(nationality_set)\n",
    "    if result: return result #if result not empty, return result\n",
    "    else: return 'correct' #if result IS empty, return 'correct'\n",
    "\n",
    "# extract groups whose sets is not identical     \n",
    "tab2_2_idctry['set_diff'] = tab2_2_idctry.apply(lambda x:\n",
    "                                                compare_country_sets_reverse(x.idctry_set, x.nationality_set), \n",
    "                                                axis = 1)\n",
    "tab2_2_error = tab2_2_idctry[tab2_2_idctry['set_diff'] != 'correct']\n",
    "\n",
    "# v-lookup in originial df \n",
    "tab2_1_error_list = tab2_1_error['key'].tolist()\n",
    "tab2_2_error_list = tab2_2_error['key'].tolist()\n",
    "tab2_error_list = tab2_1_error_list + tab2_2_error_list\n",
    "\n",
    "tab2['exist'] = tab2['key'].isin(tab2_error_list)\n",
    "tab2_columns = tab2[tab2['exist'] == True]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab2_columns['Inconsistency'] = \\\n",
    "'Same Name & DOB but Nationality <> ID proof(SG, Swiss, Italian, Germany, French, Liechtenstein)'\n",
    "\n",
    "#drop duplicates\n",
    "tab2_columns = tab2_columns.drop_duplicates(subset=['Party ID','Identification Document Type',\n",
    "                                                    'Identification Document Issue Country','Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e173787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np4: same name & dob but diff place of birth\n",
    "# location: sheet 1\n",
    "tab4 = df_natural.copy()\n",
    "tab4 = tab4[tab4['bene_only']==False]\n",
    "\n",
    "# create concat column of same party name & same DOB\n",
    "tab4['key'] = tab4['Party Name_pre'].astype(str) + \\\n",
    "              tab4['Date of Birth'].astype(str)\n",
    "\n",
    "# add a column to count no. of Place of Birth based on same Party Name & DOB\n",
    "tab4['unique_count'] = tab4.groupby(['key'])['Place of Birth'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Place of Birth \n",
    "tab4 = tab4[tab4['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab4_columns = tab4.drop_duplicates(['Party ID','key','Place of Birth'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab4_columns['Inconsistency'] = 'Same Name, DOB, Diff Place of Birth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0853295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np5: same name & dob & address type but diff address country\n",
    "# location: sheet 1\n",
    "tab5 = df_natural.copy()\n",
    "tab5 = tab5[tab5['bene_only']==False]\n",
    "tab5 = tab5[tab5['Address Type'] == 'Existing Residential Address']\n",
    "\n",
    "# create concat column of same party name, DOB\n",
    "tab5['key'] = tab5['Party Name_pre'].astype(str) + tab5['Date of Birth'].astype(str)\n",
    "\n",
    "# add a column to count no. of Address - Country based on same Party Name & DOB\n",
    "tab5['unique_count'] = tab5.groupby(['key'])['Address - Country'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Address - Country \n",
    "tab5 = tab5[tab5['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab5_columns = tab5.drop_duplicates(subset=['Party ID','key','Address - Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab5_columns['Inconsistency'] = 'Same Name, DOB, Diff Address Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np6: same name & dob & id# but diff id doc type\n",
    "# location: sheet 1\n",
    "tab6 = df_natural.copy()\n",
    "tab6 = tab6[tab6['bene_only']==False]\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab6['key'] = tab6['Party Name_pre'].astype(str) + \\\n",
    "              tab6['Date of Birth'].astype(str) + \\\n",
    "              tab6['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Type based on same party name, DOB & Identification Document Number\n",
    "tab6['unique_count'] = tab6.groupby(['key'])['Identification Document Type'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Type \n",
    "tab6 = tab6[tab6['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab6_columns = tab6.drop_duplicates(subset=['Party ID','key','Identification Document Type'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab6_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Doc Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np7: same name & dob & id# but diff id expiry\n",
    "# location: sheet 1\n",
    "tab7 = df_natural.copy()\n",
    "tab7 = tab7[tab7['bene_only']==False]\n",
    "\n",
    "#Treat ID Document Expiry Date as a string\n",
    "tab7['Identification Document Expiry Date_1'] = tab7['Identification Document Expiry Date'].astype(str)\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab7['key'] = tab7['Party Name_pre'].astype(str) + \\\n",
    "              tab7['Date of Birth'].astype(str) + \\\n",
    "              tab7['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Expiry Date based on same party name, DOB & Identification Document Number\n",
    "tab7['unique_count'] = tab7.groupby(['key'])['Identification Document Expiry Date_1'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Expiry Date \n",
    "tab7 = tab7[tab7['unique_count'] > 1]\n",
    "\n",
    "#groupby party name/DOB/ID and party RM (RM UID.1)\n",
    "tab7['unique_count_party'] = tab7.groupby(['key'])['RM UID.1'] \\\n",
    "                                 .transform('nunique')\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "tab7_columns = tab7.drop_duplicates(subset = ['Party ID','key','Identification Document Expiry Date_1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab7_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Expiry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np8: same name & dob & id# but diff id country\n",
    "# location: sheet 1\n",
    "tab8 = df_natural.copy()\n",
    "tab8 = tab8[tab8['bene_only']==False]\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab8['key'] = tab6['Party Name_pre'].astype(str) + \\\n",
    "              tab8['Date of Birth'].astype(str) + \\\n",
    "              tab8['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Issue Country based on same party name, DOB & Identification Document Number\n",
    "tab8['unique_count'] = tab8.groupby(['key'])['Identification Document Issue Country'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Issue Country \n",
    "tab8 = tab8[tab8['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab8_columns = tab8.drop_duplicates(subset=['key','Identification Document Issue Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab8_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Doc Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np9: same name & dob & id# but diff id issue date\n",
    "# location: sheet 1\n",
    "tab9 = df_natural.copy()\n",
    "tab9 = tab9[tab9['bene_only']==False]\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab9['key'] = tab9['Party Name_pre'].astype(str) + \\\n",
    "              tab9['Date of Birth'].astype(str) + \\\n",
    "              tab9['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "#Treat ID date of issue as a string\n",
    "tab9['Identification Date of Issue_1'] = tab9['Identification Date of Issue'].astype(str)\n",
    "\n",
    "\n",
    "# add a column to count no. of Identification Date of Issue based on same party name, DOB & Identification Document Number\n",
    "tab9['unique_count'] = tab9.groupby(['key'])['Identification Date of Issue_1'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Date of Issue \n",
    "tab9 = tab9[tab9['unique_count'] > 1]\n",
    "\n",
    "#groupby party name/DOB/ID and party RM (RM UID.1)\n",
    "tab9['unique_count_party'] = tab9.groupby(['key'])['RM UID.1'] \\\n",
    "                                 .transform('nunique')\n",
    "\n",
    "# remove duplicates\n",
    "tab9_columns = tab9.drop_duplicates(subset = ['key','Identification Date of Issue_1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab9_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Issue date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np10: same name & dob & id type & id coountry but diff id#\n",
    "# location: sheet 1\n",
    "tab10 = df_natural.copy()\n",
    "tab10 = tab10[tab10['bene_only']==False]\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Type, Identification Document Issue Country \n",
    "tab10['key'] = tab10['Party Name_pre'].astype(str) + \\\n",
    "               tab10['Date of Birth'].astype(str) + \\\n",
    "               tab10['Identification Document Type'].astype(str) + \\\n",
    "               tab10['Identification Document Issue Country'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Number based on same party name, DOB, Identification Document Type,Identification Document Issue Country\n",
    "tab10['unique_count'] = tab10.groupby(['key'])['Identification Document Number_pre'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Number \n",
    "tab10 = tab10[tab10['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab10_columns = tab10.drop_duplicates(subset = ['Party ID','key','Identification Document Number_pre'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab10_columns['Inconsistency'] = 'Same Name, DOB, ID Doc Type, ID Doc Country, Diff ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca43c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np11: same name & dob & party rm but diff party id\n",
    "# location: sheet 1\n",
    "tab11 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Party RM\n",
    "tab11['key'] = tab11['Party Name_pre'].astype(str) + \\\n",
    "               tab11['Date of Birth'].astype(str) + \\\n",
    "               tab11['RM Name.1'].astype(str)\n",
    "\n",
    "# add a column to count no. of Party ID based on same party name, DOB & Party RM\n",
    "tab11['unique_count'] = tab11.groupby(['key'])['Party ID'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Party ID \n",
    "tab11 = tab11[tab11['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab11_columns = tab11.drop_duplicates(subset = ['key','Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab11_columns['Inconsistency'] = 'Same Name, DOB, Party RM, Diff Party ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np12: same name & same id type & id# but diff dob \n",
    "# location: sheet 1\n",
    "tab12 = df_natural.copy()\n",
    "tab12 = tab12[tab12['bene_only']==False]\n",
    "\n",
    "#Treat DOB as a string\n",
    "tab12['Date of Birth_1'] = tab12['Date of Birth'].astype(str)\n",
    "\n",
    "# create concat column of same party name, DOB, Party RM\n",
    "tab12['key'] = tab12['Party Name_pre'].astype(str) + \\\n",
    "               tab12['Identification Document Type'].astype(str) + \\\n",
    "               tab12['Identification Document Number'].astype(str)\n",
    "\n",
    "# add a column to count no. of Party ID based on same party name, DOB & Party RM\n",
    "tab12['unique_count'] = tab12.groupby(['key'])['Date of Birth_1'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Party ID \n",
    "tab12 = tab12[tab12['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab12_columns = tab12.drop_duplicates(subset = ['key','Date of Birth'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab12_columns['Inconsistency'] = 'Same Name, Same ID Doc Type, ID #, Diff DoB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np13: Same ID Doc Type, ID #, ID Doc Country, Diff Name\n",
    "# location: sheet 2\n",
    "tab13 = df_natural.copy()\n",
    "tab13 = tab13[tab13['bene_only']==False]\n",
    "\n",
    "# Check if Identification Document Number contains invalid value\n",
    "tab13['invalid_identification_document_number'] = tab13['Identification Document Number'].isin(['[]','()', np.nan,'NA', \n",
    "                                                                                                'NA in iCare', \n",
    "                                                                                                'N.A In Icare', \n",
    "                                                                                                'n/a','na','N/A','N.A.',\n",
    "                                                                                                'N.A','indeterminata',\n",
    "                                                                                                'Indeterminata',' ','','.',\n",
    "                                                                                                '-','0','0000000','000000',\n",
    "                                                                                                'not available', \n",
    "                                                                                                'not applicable', \n",
    "                                                                                                'NIL', 'xx', 'not','XX', \n",
    "                                                                                                'Not available',\n",
    "                                                                                                '[Not Available]',\n",
    "                                                                                                '[Un Specified]', 'Na'])\n",
    "\n",
    "\n",
    "#Filter for records where ID Doc Type / ID# / ID Doc Country is not blank or invalid\n",
    "tab13 = tab13[(tab13['Identification Document Type'] != \"\") & \n",
    "              (tab13['invalid_identification_document_number'] == False) &\n",
    "              (tab13['Identification Document Issue Country'] != \"\")]\n",
    "\n",
    "# create concat column\n",
    "tab13['key'] = tab13['Identification Document Type'].astype(str) + \\\n",
    "               tab13['Identification Document Issue Country'].astype(str) + \\\n",
    "               tab13['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of party name\n",
    "tab13['unique_count'] = tab13.groupby(['key'])['Party Name_pre'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 name\n",
    "tab13 = tab13[tab13['unique_count'] > 1]\n",
    "\n",
    "# drop duplicates\n",
    "#tab13 = tab12.sort_values(by=['Party Name_pre'])\n",
    "tab13_columns = tab13.drop_duplicates(subset = ['Party ID','key','Party Name_pre'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab13_columns['Inconsistency'] = 'Same ID Doc Type, ID #, ID Doc Country, Diff Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np14: DON expiry – issue date > 2 years or missing\n",
    "# location: sheet 3\n",
    "tab14 = df_natural.copy()\n",
    "tab14 = tab14[tab14['bene_only']==False]\n",
    "\n",
    "# filter for Identification Document Type == Declaration of Nationality\n",
    "tab14 = tab14[tab14['Identification Document Type'] == 'Declaration of Nationality']\n",
    "\n",
    "# calculate time delta between Identification Document Expiry Date & Identification Document Expiry Date\n",
    "tab14['days_diff'] = tab14['Identification Document Expiry Date'] - tab14['Identification Date of Issue']\n",
    "\n",
    "# filter for days_diff > 731\n",
    "tab14_columns = tab14[(tab14['days_diff'] > dt.timedelta(731)) | \n",
    "                      (tab14['days_diff'].isna())]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab14_columns['Inconsistency'] = 'DON expiry – issue date > 2 years or missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727befa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np15: Invalid Place of Birth\n",
    "# location: sheet 3\n",
    "tab15 = df_natural.copy()\n",
    "tab15 = tab15[tab15['bene_only']==False]\n",
    "tab15 = tab15[(tab15['Identification Document Type']=='Passport') & \n",
    "              (~tab15['Identification Document Issue Country'].isin(['Japan','Korea','Switzerland','Saudi Arabia', 'Canada',\n",
    "                                                                    'Italy', 'Germany', 'France', 'Princip.Liechtenstein',\n",
    "                                                                    'Republic Of Korea',\"insert country here\"]))]\n",
    "\n",
    "# extract rows which Place of Birth contains invalid value\n",
    "tab15['invalid_place_of_birth'] = tab15['Place of Birth'].isin(['[]','()', np.nan,'NA', 'NA in iCare', 'N.A In Icare', \n",
    "                                                                'n/a','na','N/A','N.A.','N.A','indeterminata',\n",
    "                                                                'Indeterminata',' ','','.','-','0','0000000',\n",
    "                                                                '000000','not available', 'not applicable', \n",
    "                                                                'NIL', 'xx', 'not','XX', 'Not available','[Not Available]',\n",
    "                                                                '[Un Specified]', 'Europe', 'International'])\n",
    "tab15_filter = tab15[tab15['invalid_place_of_birth'] == True]\n",
    "\n",
    "tab15_columns = tab15_filter.drop_duplicates(subset = ['Party ID'])\n",
    "\n",
    "tab15_columns['Inconsistency'] = 'Invalid Place of Birth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np16: Invalid ID Doc Number\n",
    "# location: sheet 3\n",
    "tab16 = df_natural.copy()\n",
    "tab16 = tab16[tab16['bene_only']==False]\n",
    "\n",
    "# extract rows which Identification Document Number contains invalid value\n",
    "tab16['invalid_identification_document_number'] = tab16['Identification Document Number'].isin(['[]','()', np.nan,'NA', \n",
    "                                                                                                'NA in iCare', \n",
    "                                                                                                'N.A In Icare', \n",
    "                                                                                                'n/a','na','N/A','N.A.',\n",
    "                                                                                                'N.A','indeterminata',\n",
    "                                                                                                'Indeterminata',' ','','.',\n",
    "                                                                                                '-','0','0000000','000000',\n",
    "                                                                                                'not available', \n",
    "                                                                                                'not applicable', \n",
    "                                                                                                'NIL', 'xx', 'not','XX', \n",
    "                                                                                                'Not available',\n",
    "                                                                                                '[Not Available]',\n",
    "                                                                                                '[Un Specified]'])\n",
    "tab16_filter = tab16[(tab16['invalid_identification_document_number'] == True) &\n",
    "                     (tab16['Identification Document Type']!='Declaration of Nationality')]\n",
    "\n",
    "tab16_columns = tab16_filter.drop_duplicates(subset = ['Party ID',\n",
    "                                                       'Identification Document Type',\n",
    "                                                       'Identification Document Issue Country',\n",
    "                                                       'Identification Document Number'])\n",
    "\n",
    "tab16_columns['Inconsistency'] = 'Invalid ID Doc #'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd05b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np17: ID Doc Issue Country is blank when ID doc type is not blank\n",
    "# location: sheet 3\n",
    "tab17 = df_natural.copy()\n",
    "tab17 = tab17[tab17['bene_only']==False]\n",
    "\n",
    "tab17_filter = tab17[~tab17['Identification Document Type'].isna()]\n",
    "\n",
    "tab17_filter_2 = tab17_filter[tab17_filter['Identification Document Issue Country'].isna()]\n",
    "\n",
    "tab17_columns = tab17_filter_2.drop_duplicates(subset = ['Party ID',\n",
    "                                                         'Identification Document Type',\n",
    "                                                         'Identification Document Issue Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab17_columns['Inconsistency'] = 'ID Doc Issue Country is blank when ID doc type is not blank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np18: Party ID tagged to 2 portfolio RMs (Party Role = AH & BO only)\n",
    "# location: sheet 3\n",
    "tab18 = df_natural.copy()\n",
    "tab18 = tab18[tab18['bene_only']==False]\n",
    "\n",
    "tab18_filter = tab18[(tab18['Relationship (Party Role)'] == 'Account Holder') |\n",
    "                     (tab18['Relationship (Party Role)'] == 'Beneficial Owner')]\n",
    "\n",
    "# add a column to count no. of party name\n",
    "tab18_filter['unique_count'] = tab18_filter.groupby(['Party ID'])['RM UID'] \\\n",
    "                                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 party ID \n",
    "tab18_filter = tab18_filter[tab18_filter['unique_count'] > 1]\n",
    "\n",
    "#drop duplicates\n",
    "tab18_columns = tab18_filter.drop_duplicates(subset = ['Party ID','RM UID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab18_columns['Inconsistency'] = 'Party ID tagged to 2 portfolio RMs (Party Role = AH & BO only)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np22: ID only and not from acceptable countries\n",
    "# location: sheet 1\n",
    "tab22 = df_natural.copy()\n",
    "tab22 = tab22[tab22['bene_only']==False]\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab22['key'] = tab22['Party Name_pre'].astype(str) + tab22['Date of Birth'].astype(str)\n",
    "\n",
    "# count of ID doc type based on same name and DOB\n",
    "tab22['unique_count'] = tab22.groupby(['key'])['Identification Document Type'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres only 1 ID doc type and the ID doc type is ID/NRIC (pink/blue with expiry date)\n",
    "tab22_1 = tab22[(tab22['unique_count'] == 1) & (tab22['Identification Document Type'] == 'SG Pink NRIC')]\n",
    "tab22_2 = tab22[(tab22['unique_count'] == 1) & (tab22['Identification Document Type'] == 'National ID')]\n",
    "tab22_3 = tab22[(tab22['Identification Document Type'] == 'SG Blue NRIC') & (tab22['Identification Document Expiry Date'].notnull())]\n",
    "\n",
    "# Check if Nationality = Singaporean\n",
    "tab22_1_error = tab22_1[tab22_1['Nationality'] != 'Singapore']\n",
    "\n",
    "# Check if Nationality = acceptable countries\n",
    "# National ID AND Nationality = acceptable countries --> this should detect parties with SG nationality and National ID\n",
    "country_list = ['Switzerland', 'Italy', 'Germany', 'France', 'Princip.Liechtenstein', 'Thailand']\n",
    "tab22_2_error = tab22_2[~tab22_2['Nationality'].isin(country_list)]\n",
    "\n",
    "# flag if\n",
    "# 1. Blue NRIC with Expiry Date and Nationality==Singapore\n",
    "# 2. Blue NRIC with Expiry Date and Nationality > 1\n",
    "tab22_3['unique_count'] = tab22.groupby(['key'])['Nationality'].transform('nunique')\n",
    "tab22_3_error = tab22_3[((tab22_3['unique_count']==1) & (tab22_3['Nationality']=='Singapore')) | (tab22_3['unique_count']>1)]\n",
    "\n",
    "\n",
    "# v-lookup in originial df \n",
    "tab22_1_error_list = tab22_1_error['key'].tolist()\n",
    "tab22_2_error_list = tab22_2_error['key'].tolist()\n",
    "tab22_3_error_list = tab22_3_error['key'].tolist()\n",
    "tab22_error_list = tab22_1_error_list + tab22_2_error_list + tab22_3_error_list\n",
    "\n",
    "tab22['exist'] = tab22['key'].isin(tab22_error_list)\n",
    "tab22_columns = tab22[tab22['exist'] == True]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab22_columns['Inconsistency'] = 'ID only and not from acceptable countries'\n",
    "\n",
    "#drop duplicates\n",
    "tab22_columns = tab22_columns.drop_duplicates(subset = ['Party ID', 'Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np23: Blue NRIC not SG Resident\n",
    "# location: sheet 1\n",
    "tab23 = df_natural.copy()\n",
    "tab23 = tab23[tab23['bene_only']==False]\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab23['key'] = tab23['Party Name_pre'].astype(str) + tab23['Date of Birth'].astype(str)\n",
    "\n",
    "# count of ID doc type based on same name and DOB\n",
    "tab23['unique_count'] = tab23.groupby(['key'])['Identification Document Type'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres only 1 ID doc type and the ID doc type is Blue NRIC\n",
    "tab23 = tab23[(tab23['unique_count'] == 1) & \n",
    "              (tab23['Identification Document Type'] == 'SG Blue NRIC')]\n",
    "\n",
    "# Residential Pass Holder of = Singapore\n",
    "# Address type = Existing Residential Address \n",
    "# Address - Country = Singapore\n",
    "tab23_columns = tab23[~((tab23[\"Resident pass holder of\"] == 'Singapore') &\n",
    "                        (tab23[\"Address Type\"] == 'Existing Residential Address') &\n",
    "                        (tab23[\"Address - Country\"] == 'Singapore')\n",
    "                       )\n",
    "                     ]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab23_columns['Inconsistency'] = 'Blue NRIC not SG Resident'\n",
    "\n",
    "#drop duplicates\n",
    "tab23_columns = tab23_columns.drop_duplicates(subset = ['Party ID', 'Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440072ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np24: Invalid override expiry reason\n",
    "# location: sheet 5\n",
    "tab24 = df_natural.copy()\n",
    "tab24 = tab24[tab24['bene_only']==False]\n",
    "\n",
    "#create group identifier: [key]\n",
    "tab24['key']=tab24['Party Name_pre'].astype(str) + tab24['Date of Birth'].astype(str)\n",
    "\n",
    "doc_types = ['SG Pink NRIC', 'National ID', 'Passport']\n",
    "tab24 = tab24[tab24[\"Identification Document Type\"].isin(doc_types)]\n",
    "\n",
    "tab24 = tab24[(tab24['Override Expiry'] == 'Yes') & (tab24['Override Expiry Reason'] != 'Deceased')]\n",
    "\n",
    "tab24_columns = tab24.drop_duplicates(subset = ['Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab24_columns['Inconsistency'] = 'Invalid override expiry reason'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np25: override reason and deceased flag mismatch\n",
    "# location: sheet 5\n",
    "tab25 = df_natural.copy()\n",
    "tab25 = tab25[tab25['bene_only']==False]\n",
    "\n",
    "#create group identifier: [key]\n",
    "tab25['key']=tab25['Party Name_pre'].astype(str) + tab25['Date of Birth'].astype(str)\n",
    "\n",
    "doc_types = ['SG Pink NRIC', 'National ID', 'Passport']\n",
    "tab25 = tab25[tab25[\"Identification Document Type\"].isin(doc_types)]\n",
    "\n",
    "tab25 = tab25[\n",
    "              ((tab25['Override Expiry']=='Yes')&(tab25['Override Expiry Reason']=='Deceased')&(tab25['Deceased Flag']!='Yes'))\n",
    "             |((tab25['Override Expiry']=='Yes')&(tab25['Override Expiry Reason']!='Deceased')&(tab25['Deceased Flag']=='Yes'))\n",
    "             |((tab25['Override Expiry']!='Yes')&(tab25['Override Expiry Reason']=='Deceased')&(tab25['Deceased Flag']=='Yes'))\n",
    "             |((tab25['Override Expiry']!='Yes')&(tab25['Override Expiry Reason']!='Deceased')&(tab25['Deceased Flag']=='Yes'))\n",
    "             |((tab25['Override Expiry']!='Yes')&(tab25['Override Expiry Reason']=='Deceased')&(tab25['Deceased Flag']!='Yes'))\n",
    "             ]\n",
    "\n",
    "\n",
    "tab25_columns = tab25.drop_duplicates(subset = ['Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab25_columns['Inconsistency'] = 'Override and Deceased Flag Mismatch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17940e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np26: invalid ID doc type\n",
    "# location: sheet 1\n",
    "# flag only:\n",
    "# HK ID, HK Permanent ID/dependent/employment pass/s pass/social pass/student pass/green card\n",
    "# SG Blue NRIC without expiry date\n",
    "tab26 = df_natural.copy()\n",
    "tab26 = tab26[tab26['bene_only']==False] # bene only false\n",
    "tab26 = tab26[tab26['Deceased Flag']!='Yes'] # not deceased \n",
    "\n",
    "# create group identifier: [key]\n",
    "tab26['key'] = tab26['Party Name_pre'].astype(str) + tab26['Date of Birth'].astype(str)\n",
    "\n",
    "# count of ID doc type based on same name and DOB\n",
    "tab26['unique_count'] = tab26.groupby(['key'])['Identification Document Type'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# parties with only 1 id doc?\n",
    "# tab26 = tab26[tab26['unique_count']==1]\n",
    "# should be parties w/o national ID/passport\n",
    "doc_types = ['SG Pink NRIC', 'National ID', 'Passport']\n",
    "exclude_parties = tab26[tab26[\"Identification Document Type\"].isin(doc_types)]['Party ID'].tolist()\n",
    "tab26 = tab26[~tab26[\"Party ID\"].isin(exclude_parties)]\n",
    "\n",
    "\n",
    "# part 1 filtering for obvious invalid ID/others/blank\n",
    "invalid_id_list = ['HK ID', 'HK Permanent ID', 'Dependent Pass', 'Employment Pass', 'S Pass', 'Social Pass', 'Student Pass',\n",
    "                   'Green Card']\n",
    "tab26_1 = tab26[(tab26['Identification Document Type'].isin(invalid_id_list)) |\n",
    "                (tab26['Identification Document Type'].isna())]\n",
    "\n",
    "\n",
    "# part 2 blue NRIC and no expiry date\n",
    "tab26_2 = tab26[(tab26['Identification Document Type'] == 'SG Blue NRIC') &\n",
    "                (tab26['Identification Document Expiry Date'].isna())]\n",
    "\n",
    "# part 3 ID not from acceptable country (take from tab22)\n",
    "#tab26_3 = tab26[tab26.index.isin(tab22_columns.index)]\n",
    "\n",
    "# part 4 ID doc type = 'Other'\n",
    "tab26_4 = tab26[tab26['Identification Document Type'] == 'Other']\n",
    "\n",
    "# part 5 Singapore Nationality with \"national ID\"\n",
    "# should be covered in 22\n",
    "#tab26_5 = tab26[(tab26['Nationality'] == 'Singapore') & (tab26['Identification Document Type'] == 'National ID')]\n",
    "\n",
    "# join then drop duplicates\n",
    "tab26_columns = pd.concat([tab26_1, tab26_2, tab26_4])\n",
    "tab26_columns = tab26_columns.drop_duplicates(subset = ['Party ID', 'Nationality'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab26_columns['Inconsistency'] = 'Invalid ID '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab 27 - letter of undertaking + valid ID doc - flag for cleanup to remove letter of undertaking from CRM\n",
    "# sheet 1\n",
    "tab27 = df_natural.copy()\n",
    "#tab27 = tab27[tab27['bene_only']==False]\n",
    "#tab27 = tab27[tab27['Identification Document Type']=='Other']\n",
    "\n",
    "# first clean up column so we have an easier time searching\n",
    "tab27['Identification Document - Please Specify'] = tab27['Identification Document - Please Specify'].str.lower()\n",
    "\n",
    "\n",
    "tab27 = tab27.fillna('0') # can only use .str.contains() if there are no null values\n",
    "\n",
    "# regex search to find those that contain any variation of the phrase 'letter of undertaking'\n",
    "lou = ['letter of undertaking', 'lou', 'letter', 'undertaking']\n",
    "pat = '|'.join(lou)\n",
    "tab27 = tab27[tab27['Identification Document - Please Specify'].str.contains(pat)]\n",
    "\n",
    "# end\n",
    "tab27_columns = tab27.drop_duplicates(subset = ['Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab27_columns['Inconsistency'] = 'ID Docs Contains Letter of Undertaking'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c7f12",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 1\n",
    "df_1 = [tab1_columns,tab2_columns,tab4_columns,tab5_columns,tab6_columns,tab7_columns,tab8_columns,tab9_columns,\n",
    "        tab10_columns,tab11_columns,tab12_columns,tab22_columns, tab23_columns, tab26_columns]\n",
    "\n",
    "result_1 = pd.concat(df_1, join='outer', axis=0)\n",
    "result_1 = result_1.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_1['Beneficiary_role_only']=result_1['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_1 = result_1[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','RM UID.1','RM Name.1','Date of Birth','Place of Birth','Resident pass holder of',\n",
    "                    'Address Type','Address - Country','Nationality','Identification Document Type','Identification Document Issue Country',\n",
    "                    'Identification Document Number','Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Identification Document - Please Specify','Beneficiary_role_only','HK Permanent ID?']]\n",
    "\n",
    "#rename columns\n",
    "result_1.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','Party RM UID','Party RM Name','Date of Birth','Place of Birth','Resident pass holder of',\n",
    "                    'Address Type','Address - Country','Nationality','Identification Document Type','Identification Document Issue Country',\n",
    "                    'Identification Document Number','Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Identification Document - Please Specify','Beneficiary_role_only','HK Permanent ID?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e43d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 2\n",
    "result_2 = tab13_columns.sort_values(by=['key','Party Name_pre','Party ID'])\n",
    "result_2['Beneficiary_role_only']=result_2['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_2 = result_2[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','RM UID.1','RM Name.1','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Beneficiary_role_only']]\n",
    "# rename columns\n",
    "result_2.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','Party RM UID','Party RM Name','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Beneficiary_role_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 3\n",
    "df_3 = [tab14_columns,tab15_columns,tab16_columns,tab17_columns,tab18_columns]\n",
    "\n",
    "result_3 = pd.concat(df_3, join='outer', axis=0)\n",
    "result_3 = result_3.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_3['Beneficiary_role_only']=result_3['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_3 = result_3 [['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','RM UID.1','RM Name.1','RM UID','RM Name','Date of Birth','Place of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date','Identification Document - Please Specify',\n",
    "                    'Beneficiary_role_only']]\n",
    "\n",
    "# rename columns\n",
    "result_3.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','Party RM UID','Party RM Name','Portfolio RM UID','Portfolio RM Name','Date of Birth','Place of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country','Identification Document Number',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date','Identification Document - Please Specify',\n",
    "                    'Beneficiary_role_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ce454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 5\n",
    "df_5 = [tab24_columns,tab25_columns]\n",
    "\n",
    "result_5 = pd.concat(df_5, join='outer', axis=0)\n",
    "result_5 = result_5.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_5['Beneficiary_role_only']=result_5['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_5 = result_5[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID', 'Party Name','RM UID.1','RM Name.1','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Number','Identification Document Issue Country',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Override Expiry','Override Expiry Reason','Override Expiry Justification',\n",
    "                    'Deceased Flag','Beneficiary_role_only']]\n",
    "\n",
    "# rename columns\n",
    "result_5.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID', 'Party Name','Party RM UID','Party RM Name','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Number','Identification Document Issue Country',\n",
    "                    'Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Override Expiry','Override Expiry Reason','Override Expiry Justification',\n",
    "                    'Deceased Flag','Beneficiary_role_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828de17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet 6\n",
    "df_6 = [tab27_columns]\n",
    "\n",
    "result_6 = pd.concat(df_6, join='outer', axis=0)\n",
    "result_6 = result_6.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_6['Beneficiary_role_only']=result_6['Party ID'].isin(bene_only_list)\n",
    "\n",
    "# select columns\n",
    "result_6 = result_6[['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','RM UID.1','RM Name.1','Date of Birth','Place of Birth','Resident pass holder of',\n",
    "                    'Address Type','Address - Country','Nationality','Identification Document Type','Identification Document Issue Country',\n",
    "                    'Identification Document Number','Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Identification Document - Please Specify','Beneficiary_role_only']]\n",
    "\n",
    "#rename columns\n",
    "result_6.columns = ['Batch','Inconsistency','Remarks','Action Required','Action Team','Status of Cleanup','Completion Date','Valid Exception',\n",
    "                    'Party ID','Party Name','Party RM UID','Party RM Name','Date of Birth','Place of Birth','Resident pass holder of',\n",
    "                    'Address Type','Address - Country','Nationality','Identification Document Type','Identification Document Issue Country',\n",
    "                    'Identification Document Number','Identification Date of Issue','Identification Document Expiry Date',\n",
    "                    'Identification Document - Please Specify','Beneficiary_role_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb543fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ExcelWriter(output_file, mode='w',date_format = 'yyyy-mm-dd', \n",
    "                        datetime_format='yyyy-mm-dd')\n",
    "\n",
    "result_1.to_excel(writer, 'Same_name_diff_static_info', index=False) #tab1\n",
    "result_2.to_excel(writer, 'Same_ID_diff_name', index=False) #tab2\n",
    "result_3.to_excel(writer, 'incomplete_fields_or_2RM', index=False) #tab3\n",
    "result_5.to_excel(writer, 'Invalid_override_expiry', index=False) #tab5\n",
    "result_6.to_excel(writer, 'Letter of undertaking cleanup', index=False) #tab6\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
