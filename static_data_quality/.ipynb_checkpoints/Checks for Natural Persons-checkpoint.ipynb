{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d313241",
   "metadata": {},
   "source": [
    "## Natural Persons Party Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "befc9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79185a",
   "metadata": {},
   "source": [
    "### Output report name & folder to save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed3d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file: NP_InconsistencyYYMMDD.xlsx\n",
    "current_date = time.strftime(\"%Y%m%d\")\n",
    "report_name = 'NP_Inconsistency_' + current_date\n",
    "folder_to_save_files = report_name + '.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14a973",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ecb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the party_data.xlsx\n",
    "file_path = r'108536_Report_2.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1e78d",
   "metadata": {},
   "source": [
    "### Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for individuals\n",
    "df_natural = df[df['Party Type'] == 'Natural Person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing party name\n",
    "df_natural.loc[:,'Party Name_pre']=df_natural['Party Name'].copy()\n",
    "df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str \\\n",
    "                                                           .lower() \\\n",
    "                                                           .replace(r'[^\\w\\s]',\"\")\n",
    "\n",
    "#df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.strip()\n",
    "#df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.replace(\" \",\"\")\n",
    "#df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.replace('\\t','')\n",
    "#df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.replace(\",\",\"\")\n",
    "#df_natural['Party Name_pre'] = df_natural['Party Name_pre'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c5392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepocessing 'Identification Document Number' remove space & casing\n",
    "df_natural.loc[:,'Identification Document Number_pre']=df_natural['Identification Document Number'].copy()\n",
    "df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str \\\n",
    "                                                                                                   .lower() \\\n",
    "                                                                                                   .replace(r'[^\\w\\s]',\"\")\n",
    "\n",
    "#df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str.replace(\" \",\"\")\n",
    "#df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str.replace(\",\",\"\")\n",
    "#df_natural['Identification Document Number_pre'] = df_natural['Identification Document Number_pre'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72120b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create beneficiary only list\n",
    "bene_only = df_natural.groupby('Party ID')['Relationship (Party Role)'] \\\n",
    "                      .agg(set) \\\n",
    "                      .reset_index(name = 'role_set')\n",
    "\n",
    "bene_only = bene_only[bene_only['role_set'] == {'Beneficiary'}]\n",
    "bene_only_list = bene_only['Party ID'].to_list()\n",
    "\n",
    "df_natural['bene_only'] = df_natural['Party ID'].isin(bene_only_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764da265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "df_natural['Date of Birth']  = pd.to_datetime(df_natural['Date of Birth'], format='%Y-%m-%d', errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b50fc7",
   "metadata": {},
   "source": [
    "### S1: Same name & DOB but Passport ID Doc Ctry != Nationality (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f037ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = df_natural.copy()\n",
    "\n",
    "# create list of Party IDs with HK permanent ID\n",
    "HK_permID = tab1[tab1['Identification Document Type'] == 'HK Permanent ID'].drop_duplicates(subset = ['Party ID'])\n",
    "HK_permID_list = HK_permID['Party ID'].tolist()\n",
    "\n",
    "# create list of British Overseas Territories Passports\n",
    "Brit_set = {'Anguilla','Bermuda','Virgin Islands','Cayman Islands','Gibraltar','Guernsey','Jersey','Manx','Montserrat',\n",
    "            'Saint Helena','Turks and Calcos Islands','Isle of Man'}\n",
    "\n",
    "# select identification Document Type ==  'Passport'\n",
    "tab1 = tab1[tab1['Identification Document Type'] == 'Passport']\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab1['key'] = tab1['Party Name_pre'].astype(str) + tab1['Date of Birth'].astype(str)\n",
    "\n",
    "# replace Brit Overseas Territories Passports with UK passports\n",
    "tab1_Brit=tab1.copy()\n",
    "tab1_Brit.loc[tab1['Identification Document Issue Country'].isin(Brit_set), \n",
    "              'Identification Document Issue Country'] = \"United Kingdom\"\n",
    "\n",
    "# create group identifier: [passport key]\n",
    "tab1['passport_key'] = tab1_Brit['Party Name_pre'].astype(str) + \\\n",
    "                       tab1_Brit['Date of Birth'].astype(str) + \\\n",
    "                       tab1_Brit['Identification Document Issue Country'].astype(str)\n",
    "\n",
    "# create group identifier: [nationality key]\n",
    "tab1['nationality_key'] = tab1['Party Name_pre'].astype(str) + \\\n",
    "                          tab1['Date of Birth'].astype(str) + \\\n",
    "                          tab1['Nationality'].astype(str)\n",
    "\n",
    "# create list of passports\n",
    "tab1_pp_list = tab1.passport_key.tolist()\n",
    "\n",
    "# create list of nationalities\n",
    "tab1_nationality_list = tab1.nationality_key.tolist()\n",
    "\n",
    "# check if passports can be found in list of nationalities, flag if cannot be found\n",
    "tab1['flag'] = ~(tab1['passport_key'].isin(tab1_nationality_list))\n",
    "\n",
    "# check if nationalities can be found in list of passports, flag if cannot be found\n",
    "tab1['flag2'] = ~(tab1['nationality_key'].isin(tab1_pp_list))\n",
    "\n",
    "# filter for records where passports cannot be found in nationalities and vice versa\n",
    "tab1_filter = tab1[(tab1['flag'] == True) | (tab1['flag2'] == True)]\n",
    "          \n",
    "# create list of parties to flag based on \"key\" [party name + DOB]\n",
    "tab1_filter_list = tab1_filter.key.tolist()\n",
    "\n",
    "# retrieve all records that is in list of parties to flag\n",
    "tab1_columns = tab1[(tab1['key'].isin(tab1_filter_list))]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab1_columns['Inconsistency'] = 'Same Name & DOB but Passport ID Doc Ctry <> Nationality'\n",
    "\n",
    "#indicate if party ID has HK Perm ID, if nationality- HK\n",
    "tab1_columns['HK Permanent ID?'] = \"\"\n",
    "tab1_columns.loc[((tab1_columns['Party ID'].isin(HK_permID_list)) & \n",
    "                  (tab1_columns['Nationality'] == \"Hong Kong\")), 'HK Permanent ID?'] = 'True'\n",
    "\n",
    "#drop duplicates\n",
    "tab1_columns = tab1_columns.drop_duplicates(subset = ['Party ID','Identification Document Type',\n",
    "                                                      'Identification Document Issue Country','Nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7725a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes: (dated: ??)\n",
    "# future enhancement: check that the country of 'resident pass holder of' matches the country of 'id type'\n",
    "# this is because parties may have more than 1 id type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ded76",
   "metadata": {},
   "source": [
    "### S2: same name & DOB but Nationality <> ID proof (SG, Swiss, Italian, Germany, French, Liechtenstein)  (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37bac0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab2 = df_natural.copy()\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab2['key'] = tab2['Party Name_pre'].astype(str) + tab2['Date of Birth'].astype(str)\n",
    "\n",
    "\n",
    "# 2.1 checking for sg pink nric\n",
    "# select rows with 'sg pink nric'\n",
    "tab2_1 = tab2[tab2['Identification Document Type'] == 'SG Pink NRIC']\n",
    "\n",
    "# create a [Nationality] set for each group\n",
    "tab2_nationality = tab2_1.groupby('key')['Nationality'] \\\n",
    "                         .agg(set) \\\n",
    "                         .reset_index(name='nationality_set')\n",
    "\n",
    "nationality_set = tab2_nationality.nationality_set.tolist()\n",
    "\n",
    "# def function to check if Singapore exist in [Nationality]\n",
    "def check_singapore(nationality_set):\n",
    "    \n",
    "    #check if Singapore exists in the set of Nationality\n",
    "    singapore_set = {'Singapore'}\n",
    "   \n",
    "    result = nationality_set.difference(singapore_set)\n",
    "    if 'Singapore' in nationality_set: return 'correct'\n",
    "    else: return result\n",
    "\n",
    "# apply function\n",
    "tab2_nationality['check_singapore'] = tab2_nationality['nationality_set'].apply(lambda x: check_singapore(x))\n",
    "tab2_1_error = tab2_nationality[tab2_nationality['check_singapore'] != 'correct']\n",
    "\n",
    "\n",
    "# 2.2 checking for national id of eu countries\n",
    "# select rows  with national id of eu countries\n",
    "nationality_list = ['Switzerland', 'Italy', 'Germany', 'France', 'Liechtenstein']\n",
    "tab2_2 = tab2[tab2['Identification Document Type'] == 'National ID']\n",
    "tab2_2_filter = tab2_2[(tab2_2['Identification Document Issue Country'].isin(nationality_list))]\n",
    "\n",
    "# create a [Nationality] set for each group\n",
    "tab2_2_nationality = tab2_2_filter.groupby('key')['Nationality'] \\\n",
    "                                  .agg(set) \\\n",
    "                                  .reset_index(name = 'nationality_set')\n",
    "\n",
    "tab2_nationality_set = tab2_2_nationality['nationality_set'].tolist()\n",
    "\n",
    "# create a [Identification Document Issue Country] set for each group\n",
    "tab2_2_idctry = tab2_2_filter.groupby('key')['Identification Document Issue Country'] \\\n",
    "                             .agg(set) \\\n",
    "                             .reset_index(name='idctry_set')\n",
    "tab2_2_idctry['nationality_set'] = tab2_nationality_set\n",
    "\n",
    "# compare two sets: set(idcrty) - set(nationality)\n",
    "def compare_country_sets_reverse(idctry_set, nationality_set):\n",
    "    \n",
    "    #compare the difference between set of passport ID doc ctry and set of nationality\n",
    "    result = idctry_set.difference(nationality_set)\n",
    "    if result: return 'correct'\n",
    "    else: return result\n",
    "\n",
    "# el notes: (dated: 20 aug 2023)\n",
    "# set_diff will only be created IF there are parties with nationality = swiss/france/german/etc.\n",
    "# should add if/else clause here: if no such parties are preset, skip this section.\n",
    "# this will help us avoid an error when there are no parties with eu nationality\n",
    "    \n",
    "# extract groups whose sets is not identical     \n",
    "tab2_2_idctry['set_diff'] = tab2_2_idctry.apply(lambda x: compare_country_sets_reverse(x.idctry_set, x.nationality_set), \n",
    "                                                axis = 1)\n",
    "tab2_2_error = tab2_2_idctry[tab2_2_idctry['set_diff'] != 'correct']\n",
    "\n",
    "# combine 2.1 and 2.2\n",
    "# v-lookup in originial df \n",
    "tab2_1_error_list = tab2_1_error['key'].tolist()\n",
    "tab2_2_error_list = tab2_2_error['key'].tolist()\n",
    "tab2_error_list = tab2_1_error_list + tab2_2_error_list\n",
    "tab2['exist'] = tab2['key'].isin(tab2_error_list)\n",
    "tab2_columns = tab2[tab2['exist'] == True]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab2_columns['Inconsistency'] = 'Same Name & DOB but Nationality <> ID proof(SG, Swiss, Italian, Germany, French, Liechtenstein)'\n",
    "\n",
    "#drop duplicates\n",
    "tab2_columns = tab2_columns.drop_duplicates(subset=['Party ID',\n",
    "                                                    'Identification Document Type',\n",
    "                                                    'Identification Document Issue Country',\n",
    "                                                    'Nationality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea259d",
   "metadata": {},
   "source": [
    "### S3: Same Name, DOB, Diff VC status (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fcfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab3 = df_natural.copy()\n",
    "\n",
    "#create list of Party Ids in scope for declaring VC status\n",
    "VC_role=df_natural.copy()\n",
    "VC_role['vc_role'] = 0\n",
    "\n",
    "#filter for only roles in scope for VC status: Individuals - AH, BO, LPOA, GPOA; Non-Individuals - LPOA, AR.\n",
    "relatipnship_list_indv = ['Account Holder', 'Beneficial Owner', 'Limited Power of Attorney', 'General Power of Attorney']\n",
    "relationship_list_nonindv = ['Limited Power of Attorney', 'Authorised Representative']\n",
    "VC_role.loc[((VC_role['Relationship Type']=='Individual') & \n",
    "             (VC_role['Relationship Type'].isin(relatipnship_list_indv))) |\n",
    "            ((VC_role['Relationship Type']!='Individual') &\n",
    "             (VC_role['Relationship Type'].isin(relatipnship_list_nonindv))),\n",
    "            'vc_role']=1\n",
    "\n",
    "VC_role = VC_role[VC_role['vc_role'] == 1]\n",
    "VC_list = VC_role['Party ID'].to_list()\n",
    "VC_list = list(dict.fromkeys(VC_list))\n",
    "\n",
    "#filter for only parties in scope for declaring VC status\n",
    "tab3['VC_role'] = tab3['Party ID'].isin(VC_list)\n",
    "tab3 = tab3[tab3['VC_role']==True]\n",
    "# create concat column of same party name & same DOB\n",
    "tab3['key'] = tab3['Party Name_pre'].astype(str) + tab3['Date of Birth'].astype(str)\n",
    "\n",
    "# add a column to count no. of Vulnerable Client based on same Party Name & DOB\n",
    "tab3['unique_count'] = tab3.groupby(['key'])['Vulnerable Client'].transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Vulnerable Client \n",
    "tab3 = tab3[tab3['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab3_columns = tab3.drop_duplicates(subset = ['Party ID','key','Vulnerable Client'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab3_columns['Inconsistency'] = 'Same Name, DOB, Diff VC status'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2070d5",
   "metadata": {},
   "source": [
    "### S4: Same Name, DOB, Diff Place of Birth (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6c775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab4 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name & same DOB\n",
    "tab4['key'] = tab4['Party Name_pre'].astype(str) + tab4['Date of Birth'].astype(str)\n",
    "\n",
    "# add a column to count no. of Place of Birth based on same Party Name & DOB\n",
    "tab4['unique_count'] = tab4.groupby(['key'])['Place of Birth'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Place of Birth \n",
    "tab4 = tab4[tab4['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab4_columns = tab4.drop_duplicates(['Party ID','key','Place of Birth'])\n",
    "\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab4_columns['Inconsistency'] = 'Same Name, DOB, Diff Place of Birth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0582b0",
   "metadata": {},
   "source": [
    "### S5: Same Name, DOB, Add Type, Diff Address Country (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7456e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab5 = df_natural.copy()\n",
    "tab5 = tab5[tab5['Address Type'] == 'Existing Residential Address']\n",
    "\n",
    "# create concat column of same party name, DOB\n",
    "tab5['key'] = tab5['Party Name_pre'].astype(str) + tab5['Date of Birth'].astype(str)\n",
    "\n",
    "# add a column to count no. of Address - Country based on same Party Name & DOB\n",
    "tab5['unique_count'] = tab5.groupby(['key'])['Address - Country'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Address - Country \n",
    "tab5 = tab5[tab5['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab5_columns = tab5.drop_duplicates(subset=['Party ID','key','Address - Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab5_columns['Inconsistency'] = 'Same Name, DOB, Diff Address Country'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca6c77",
   "metadata": {},
   "source": [
    "### S6: Same Name, DOB, ID #, Diff ID Doc Type (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "241ba8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab6 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab6['key'] = tab6['Party Name_pre'].astype(str) + \\\n",
    "              tab6['Date of Birth'].astype(str) + \\\n",
    "              tab6['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Type based on same party name, DOB & Identification Document Number\n",
    "tab6['unique_count'] = tab6.groupby(['key'])['Identification Document Type'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Type \n",
    "tab6 = tab6[tab6['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab6_columns = tab6.drop_duplicates(subset=['Party ID','key','Identification Document Type'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab6_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Doc Type'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc00eac",
   "metadata": {},
   "source": [
    "### S7: Same Name, DOB, ID #, Diff ID Expiry (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d37871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab7 = df_natural.copy()\n",
    "#Treat ID Document Expiry Date as a string\n",
    "tab7['Identification Document Expiry Date_1'] = tab7['Identification Document Expiry Date'].astype(str)\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab7['key'] = tab7['Party Name_pre'].astype(str) + \\\n",
    "              tab7['Date of Birth'].astype(str) + \\\n",
    "              tab7['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Expiry Date based on same party name, DOB & Identification Document Number\n",
    "tab7['unique_count'] = tab7.groupby(['key'])['Identification Document Expiry Date_1'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Expiry Date \n",
    "tab7 = tab7[tab7['unique_count'] > 1]\n",
    "\n",
    "\n",
    "# el notes: (dated: 25 may 2023) - Added the following segment\n",
    "#- filter DON AND same name/dob/ID AND different RM > exclude\n",
    "\n",
    "#groupby party name/DOB/ID and party RM (RM UID.1)\n",
    "tab7['unique_count_party'] = tab7.groupby(['key'])['RM UID.1'] \\\n",
    "                                 .transform('nunique')\n",
    "\n",
    "tab7_exclude = tab7[(tab7['unique_count_party'] > 1) & \n",
    "                    (tab7['Identification Document Type'] == 'Declaration of Nationality')]\n",
    "\n",
    "\n",
    "#drop rows to be excluded\n",
    "tab7 = tab7.drop(tab7_exclude.index)\n",
    "\n",
    "# remove duplicates\n",
    "tab7_columns = tab7.drop_duplicates(subset = ['Party ID','key','Identification Document Expiry Date_1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab7_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Expiry'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda6c73",
   "metadata": {},
   "source": [
    "### S8: Same Name, DOB, ID #, Diff ID Doc Country (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf72c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab8 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab8['key'] = tab6['Party Name_pre'].astype(str) + \\\n",
    "              tab8['Date of Birth'].astype(str) + \\\n",
    "              tab8['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of Identification Document Issue Country based on same party name, DOB & Identification Document Number\n",
    "tab8['unique_count'] = tab8.groupby(['key'])['Identification Document Issue Country'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Issue Country \n",
    "tab8 = tab8[tab8['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab8_columns = tab8.drop_duplicates(subset = ['key','Identification Document Issue Country'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab8_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Doc Country'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f48b1",
   "metadata": {},
   "source": [
    "### S9: Same Name, DOB, ID #, Diff ID Issue date (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cd37da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab9 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Number\n",
    "tab9['key'] = tab9['Party Name_pre'].astype(str) + \\\n",
    "              tab9['Date of Birth'].astype(str) + \\\n",
    "              tab9['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "#Treat ID date of issue as a string\n",
    "tab9['Identification Date of Issue_1'] = tab9['Identification Date of Issue'].astype(str)\n",
    "\n",
    "\n",
    "# add a column to count no. of Identification Date of Issue based on same party name, DOB & Identification Document Number\n",
    "tab9['unique_count'] = tab9.groupby(['key'])['Identification Date of Issue_1'] \\\n",
    "                           .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Date of Issue \n",
    "tab9 = tab9[tab9['unique_count'] > 1]\n",
    "\n",
    "# el notes: (dated 25 may 2023) - Added below segment\n",
    "\n",
    "#groupby party name/DOB/ID and party RM (RM UID.1)\n",
    "tab9['unique_count_party'] = tab9.groupby(['key'])['RM UID.1'] \\\n",
    "                                 .transform('nunique')\n",
    "\n",
    "tab9_exclude = tab9[(tab9['unique_count_party'] > 1) & \n",
    "                    (tab9['Identification Document Type'] == 'Declaration of Nationality')]\n",
    "\n",
    "#drop rows to be excluded\n",
    "tab9 = tab9.drop(tab9_exclude.index)\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "tab9_columns = tab9.drop_duplicates(subset = ['key','Identification Date of Issue_1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab9_columns['Inconsistency'] = 'Same Name, DOB, ID #, Diff ID Issue date'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121d60b",
   "metadata": {},
   "source": [
    "### S10: Same Name, DOB, ID Doc Type, ID Doc Country, Diff ID # (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3cd056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab10 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Identification Document Type, Identification Document Issue Country \n",
    "tab10['key'] = tab10['Party Name_pre'].astype(str) + \\\n",
    "               tab10['Date of Birth'].astype(str) + \\\n",
    "               tab10['Identification Document Type'].astype(str) + \\\n",
    "               tab10['Identification Document Issue Country'].astype(str)\n",
    "\n",
    "# add a column to count no. of ID Number based on same party name, DOB, ID Type, ID Country\n",
    "tab10['unique_count'] = tab10.groupby(['key'])['Identification Document Number_pre'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Number \n",
    "tab10 = tab10[tab10['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab10_columns = tab10.drop_duplicates(subset = ['Party ID','key','Identification Document Number_pre'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab10_columns['Inconsistency'] = 'Same Name, DOB, ID Doc Type, ID Doc Country, Diff ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f7dfd",
   "metadata": {},
   "source": [
    "### S11: Same Name, DOB, Party RM, Diff Party ID (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c4642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab11 = df_natural.copy()\n",
    "\n",
    "# create concat column of same party name, DOB, Party RM\n",
    "tab11['key'] = tab11['Party Name_pre'].astype(str) + \\\n",
    "               tab11['Date of Birth'].astype(str) + \\\n",
    "               tab11['RM Name.1'].astype(str)\n",
    "\n",
    "# add a column to count no. of Party ID based on same party name, DOB & Party RM\n",
    "tab11['unique_count'] = tab11.groupby(['key'])['Party ID'] \\\n",
    "                             .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Party ID \n",
    "tab11 = tab11[tab11['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab11_columns = tab11.drop_duplicates(subset = ['key','Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab11_columns['Inconsistency'] = 'Same Name, DOB, Party RM, Diff Party ID'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcce1a7",
   "metadata": {},
   "source": [
    "### S11A: Same Name, Same ID Doc Type, ID #, Diff DoB (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8adeadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab11a = df_natural.copy()\n",
    "#Treat DOB as a string\n",
    "tab11a['Date of Birth_1'] = tab11a['Date of Birth'].astype(str)\n",
    "\n",
    "# create concat column of same party name, DOB, Party RM\n",
    "tab11a['key'] = tab11a['Party Name_pre'].astype(str) + \\\n",
    "                tab11a['Identification Document Type'].astype(str) + \\\n",
    "                tab11a['Identification Document Number'].astype(str)\n",
    "\n",
    "# add a column to count no. of Party ID based on same party name, DOB & Party RM\n",
    "tab11a['unique_count'] = tab11a.groupby(['key'])['Date of Birth_1'] \\\n",
    "                               .transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Party ID \n",
    "tab11a = tab11a[tab11a['unique_count'] > 1]\n",
    "\n",
    "# remove duplicates\n",
    "tab11a_columns = tab11a.drop_duplicates(subset = ['key','Date of Birth'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab11a_columns['Inconsistency'] = 'Same Name, Same ID Doc Type, ID #, Diff DoB'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0420d7",
   "metadata": {},
   "source": [
    "### S12: Same ID Doc Type, ID #, ID Doc Country, Diff Name (Sheet 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f14f75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab12 = df_natural.copy()\n",
    "\n",
    "# Check if Identification Document Number contains invalid value\n",
    "tab12['invalid_identification_document_number'] = tab12['Identification Document Number'].isin(['[]','()', np.nan,'NA', \n",
    "                                                                                                'NA in iCare', \n",
    "                                                                                                'N.A In Icare', \n",
    "                                                                                                'n/a','na','N/A','N.A.',\n",
    "                                                                                                'N.A','indeterminata',\n",
    "                                                                                                'Indeterminata',' ','','.',\n",
    "                                                                                                '-','0','0000000','000000',\n",
    "                                                                                                'not available', \n",
    "                                                                                                'not applicable', \n",
    "                                                                                                'NIL', 'xx', 'not','XX', \n",
    "                                                                                                'Not available',\n",
    "                                                                                                '[Not Available]',\n",
    "                                                                                                '[Un Specified]'])\n",
    "\n",
    "\n",
    "#Filter for records where ID Doc Type / ID# / ID Doc Country is not blank or invalid\n",
    "tab12 = tab12[(tab12['Identification Document Type'] != \"\") & \n",
    "              (tab12['invalid_identification_document_number'] == False) &\n",
    "              (tab12['Identification Document Issue Country'] != \"\")]\n",
    "\n",
    "# create concat column\n",
    "tab12['key'] = tab12['Identification Document Type'].astype(str) + \\\n",
    "               tab12['Identification Document Issue Country'].astype(str) + \\\n",
    "               tab12['Identification Document Number_pre'].astype(str)\n",
    "\n",
    "# add a column to count no. of party name\n",
    "tab12['unique_count'] = tab12.groupby(['key'])['Party Name_pre'].transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 name\n",
    "tab12 = tab12[tab12['unique_count'] > 1]\n",
    "\n",
    "# drop duplicates\n",
    "#tab12 = tab12.sort_values(by=['Party Name_pre'])\n",
    "tab12_columns = tab12.drop_duplicates(subset=['Party ID','key','Party Name_pre'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab12_columns['Inconsistency'] = 'Same ID Doc Type, ID #, ID Doc Country, Diff Name'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d372c4",
   "metadata": {},
   "source": [
    "### S13: DON expiry – issue date != 2 years or missing (Sheet 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66668aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab13 = df_natural.copy()\n",
    "\n",
    "# filter for Identification Document Type == Declaration of Nationality\n",
    "tab13 = tab13[tab13['Identification Document Type']=='Declaration of Nationality']\n",
    "\n",
    "# calculate time delta between Identification Document Expiry Date & Identification Document Expiry Date\n",
    "tab13['days_diff'] = tab13['Identification Document Expiry Date'] - tab13['Identification Date of Issue']\n",
    "\n",
    "# EL 25/05/2023 - Included OR condition to check if issue/expiry date is blank\n",
    "# filter for days_diff > 731\n",
    "tab13_columns = tab13[(tab13['days_diff'] > dt.timedelta(731)) | (tab13['days_diff'].isna())]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab13_columns['Inconsistency'] = 'DON expiry – issue date != 2 years or missing'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da1f71",
   "metadata": {},
   "source": [
    "### S14: Invalid Place of Birth (Sheet 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c44f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab14 = df_natural.copy()\n",
    "\n",
    "# extract rows which Place of Birth contains invalid value\n",
    "tab14['invalid_place_of_birth'] = tab14['Place of Birth'].isin(['[]','()', np.nan,'NA', 'NA in iCare', 'N.A In Icare', \n",
    "                                                                'n/a','na','N/A','N.A.','N.A','indeterminata',\n",
    "                                                                'Indeterminata',' ','','.','-','0','0000000',\n",
    "                                                                '000000','not available', 'not applicable', \n",
    "                                                                'NIL', 'xx', 'not','XX', 'Not available','[Not Available]','[Un Specified]'])\n",
    "tab14_filter = tab14[tab14['invalid_place_of_birth']==True]\n",
    "\n",
    "tab14_columns = tab14_filter.drop_duplicates(subset=['Party ID'])\n",
    "\n",
    "tab14_columns['Inconsistency'] = 'Invalid Place of Birth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3c04a",
   "metadata": {},
   "source": [
    "### S15: Invalid ID Doc Number (Sheet 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e552bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab15 = df_natural.copy()\n",
    "\n",
    "\n",
    "\n",
    "# extract rows which Identification Document Number contains invalid value\n",
    "tab15['invalid_identification_document_number'] = tab15['Identification Document Number'].isin(['[]','()', np.nan,'NA', \n",
    "                                                                                                'NA in iCare', \n",
    "                                                                                                'N.A In Icare', \n",
    "                                                                                                'n/a','na','N/A','N.A.',\n",
    "                                                                                                'N.A','indeterminata',\n",
    "                                                                                                'Indeterminata',' ','','.',\n",
    "                                                                                                '-','0','0000000','000000',\n",
    "                                                                                                'not available', \n",
    "                                                                                                'not applicable', \n",
    "                                                                                                'NIL', 'xx', 'not','XX', \n",
    "                                                                                                'Not available',\n",
    "                                                                                                '[Not Available]',\n",
    "                                                                                                '[Un Specified]'])\n",
    "tab15_filter = tab15[tab15['invalid_identification_document_number']==True]\n",
    "tab15_columns = tab15_filter.drop_duplicates(subset=['Party ID','Identification Document Type',\n",
    "                              'Identification Document Issue Country',\n",
    "                              'Identification Document Number'])\n",
    "\n",
    "\n",
    "tab15_columns['Inconsistency'] = 'Invalid ID Doc #'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9f818",
   "metadata": {},
   "source": [
    "### S16: ID Doc Issue Country is blank when ID doc type is not blank (Sheet 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eb6af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab16 = df_natural.copy()\n",
    "tab16_filter = tab16[tab16['Identification Document Type']!=np.nan]\n",
    "tab16_filter_2 = tab16_filter[tab16_filter['Identification Document Issue Country']==np.nan]\n",
    "tab16_columns = tab16_filter_2.drop_duplicates(subset=['Party ID','Identification Document Type','Identification Document Issue Country'])\n",
    "\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab16_columns['Inconsistency'] = 'ID Doc Issue Country is blank when ID doc type is not blank'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be4522",
   "metadata": {},
   "source": [
    "### S17: Party ID tagged to 2 portfolio RMs (Party Role = AH & BO only) (Sheet 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fc54c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab17 = df_natural.copy()\n",
    "tab17_filter = tab17[(tab17['Relationship (Party Role)']=='Account Holder')|(tab17['Relationship (Party Role)']=='Beneficial Owner')]\n",
    "\n",
    "# add a column to count no. of party name\n",
    "tab17_filter['unique_count'] = tab17_filter.groupby(['Party ID'])['RM UID'].transform('nunique')\n",
    "\n",
    "# keep only rows where theres > 1 Identification Document Type \n",
    "tab17_filter = tab17_filter[tab17_filter['unique_count'] > 1]\n",
    "\n",
    "#drop duplicates\n",
    "tab17_columns = tab17_filter.drop_duplicates(subset=['Party ID','RM UID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab17_columns['Inconsistency'] = 'Party ID tagged to 2 portfolio RMs (Party Role = AH & BO only)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead97dbf",
   "metadata": {},
   "source": [
    "### S18: Party ID tagged to multiple Party RMs (Sheet 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7bd4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab18 = df_natural.copy()\n",
    "\n",
    "tab18['unique_count'] = tab18.groupby(['Party ID'])['RM UID.1'].transform('nunique')\n",
    "tab18 = tab18[tab18['unique_count'] > 1]\n",
    "tab18 = tab18.sort_values(by=['Party Name_pre'])\n",
    "tab18_columns = tab18.drop_duplicates(subset=['Party ID','RM UID.1'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab18_columns['Inconsistency'] = 'Party ID tagged to multiple Party RMs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983deac4",
   "metadata": {},
   "source": [
    "### S19: AH not tagged as BO (Sheet 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea83c41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab19 = df_natural.copy()\n",
    "tab19_filter = tab19[tab19['Relationship Type']=='Individual']\n",
    "tab19_filter = tab19_filter[(tab19_filter['Relationship Sub-Type'] == 'Single')|(tab19_filter['Relationship Sub-Type'] == 'Joint')]\n",
    "\n",
    "# extract all parties whose party role == Account Holder OR Beneficial Owner\n",
    "tab19_filter = tab19_filter[(tab19_filter['Relationship (Party Role)'] == 'Account Holder')|(tab19_filter['Relationship (Party Role)'] == 'Beneficial Owner')]\n",
    "\n",
    "# count if there are 2 unique values for each party ID\n",
    "tab19_filter['unique_count'] = tab19_filter.groupby(['Party ID','Portfolio Number'])['Relationship (Party Role)'].transform('nunique')\n",
    "\n",
    "# extract parties who only have 1 party role\n",
    "tab19_filter = tab19_filter[tab19_filter['unique_count'] <= 1]\n",
    "\n",
    "# extract parties whose party role == Account Holder\n",
    "tab19_filter['AH'] = tab19_filter['Relationship (Party Role)'].isin(['Account Holder'])\n",
    "tab19_columns = tab19_filter[tab19_filter['AH']==True]\n",
    "tab19_columns = tab19_columns.drop_duplicates(subset=['Party ID','Portfolio Number','Relationship (Party Role)'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab19_columns['Inconsistency'] = 'AH not tagged as BO'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d751f",
   "metadata": {},
   "source": [
    "### S20: BO not tagged as AH (Sheet 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1b10c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab20 = df_natural.copy()\n",
    "tab20_filter = tab20[tab20['Relationship Type']=='Individual']\n",
    "tab20_filter = tab20_filter[(tab20_filter['Relationship Sub-Type'] == 'Single')|(tab20_filter['Relationship Sub-Type'] == 'Joint')]\n",
    "\n",
    "# extract all parties whose party role == Account Holder OR Beneficial Owner\n",
    "tab20_filter = tab20_filter[(tab20_filter['Relationship (Party Role)'] == 'Account Holder')|(tab20_filter['Relationship (Party Role)'] == 'Beneficial Owner')]\n",
    "\n",
    "# count if there are 2 unique values for each party ID\n",
    "tab20_filter['unique_count'] = tab20_filter.groupby(['Party ID','Portfolio Number'])['Relationship (Party Role)'].transform('nunique')\n",
    "\n",
    "# extract parties who only have 1 party role\n",
    "tab20_filter = tab20_filter[tab20_filter['unique_count'] <= 1]\n",
    "\n",
    "# extract parties whose party role == Account Holder\n",
    "tab20_filter['BO'] = tab20_filter['Relationship (Party Role)'].isin(['Beneficial Owner'])\n",
    "tab20_columns = tab20_filter[tab20_filter['BO']==True]\n",
    "\n",
    "tab20_columns = tab20_columns.drop_duplicates(subset=['Party ID','Portfolio Number','Relationship (Party Role)'])\n",
    "tab20_columns['Inconsistency'] = 'BO not tagged as AH'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820bf49c",
   "metadata": {},
   "source": [
    "### S21: ID only and not from acceptable countries (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b86b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab21 = df_natural.copy()\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab21['key'] = tab21['Party Name_pre'].astype(str) + tab21['Date of Birth'].astype(str)\n",
    "\n",
    "# count of ID doc type based on same name and DOB\n",
    "tab21['unique_count'] = tab21.groupby(['key'])['Identification Document Type'].transform('nunique')\n",
    "# keep only rows where theres only 1 ID doc type and the ID doc type is ID/NRIC\n",
    "tab21_1 = tab21[(tab21['unique_count'] == 1) & (tab21['Identification Document Type'] == 'SG Pink NRIC')]\n",
    "tab21_2 = tab21[(tab21['unique_count'] == 1) & (tab21['Identification Document Type'] == 'National ID')]\n",
    "\n",
    "# Check if Nationality = Singaporean\n",
    "tab21_1_error = tab21_1[tab21_1['Nationality'] != 'Singapore']\n",
    "\n",
    "# Check if Nationality =  \n",
    "country_list = ['Switzerland', 'Italy', 'Germany', 'France', 'Princip.Liechtenstein', 'Thailand', 'Singapore']\n",
    "tab21_2_error = tab21_2[~tab21_2['Nationality'].isin(country_list)]\n",
    "\n",
    "# v-lookup in originial df \n",
    "tab21_1_error_list = tab21_1_error['key'].tolist()\n",
    "tab21_2_error_list = tab21_2_error['key'].tolist()\n",
    "tab21_error_list = tab21_1_error_list + tab21_2_error_list\n",
    "tab21['exist'] = tab21['key'].isin(tab21_error_list)\n",
    "tab21_columns = tab21[tab21['exist']==True]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab21_columns['Inconsistency'] = 'ID only and not from acceptable countries'\n",
    "#drop duplicates\n",
    "tab21_columns = tab21_columns.drop_duplicates(subset=['Party ID', 'Nationality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ffc52",
   "metadata": {},
   "source": [
    "### S22: Blue NRIC not SG Resident (Sheet 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2ae2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab22 = df_natural.copy()\n",
    "\n",
    "# create group identifier: [key]\n",
    "tab22['key'] = tab22['Party Name_pre'].astype(str) + tab22['Date of Birth'].astype(str)\n",
    "\n",
    "# count of ID doc type based on same name and DOB\n",
    "tab22['unique_count'] = tab22.groupby(['key'])['Identification Document Type'].transform('nunique')\n",
    "# keep only rows where theres only 1 ID doc type and the ID doc type is Blue NRIC\n",
    "tab22 = tab22[(tab22['unique_count'] == 1) & (tab22['Identification Document Type'] == 'SG Blue NRIC')]\n",
    "\n",
    "# Residential Pass Holder of = Singapore\n",
    "# Address type = Existing Residential Address \n",
    "# Address - Country = Singapore\n",
    "tab22_columns = tab22[~((tab22[\"Resident pass holder of\"] == 'Singapore') &\n",
    "                        (tab22[\"Address Type\"] == 'Existing Residential Address') &\n",
    "                        (tab22[\"Address - Country\"] == 'Singapore')\n",
    "                       )]\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab22_columns['Inconsistency'] = 'Blue NRIC not SG Resident'\n",
    "#drop duplicates\n",
    "tab22_columns = tab22_columns.drop_duplicates(subset=['Party ID', 'Nationality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78900",
   "metadata": {},
   "source": [
    "### S23: Invalid override expiry reason (Sheet 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59a3c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab23 = df_natural.copy()\n",
    "\n",
    "#create group identifier: [key]\n",
    "tab23['key']=tab23['Party Name_pre'].astype(str) + tab23['Date of Birth'].astype(str)\n",
    "\n",
    "doc_types = ['SG Pink NRIC', 'National ID', 'Passport']\n",
    "\n",
    "tab23 = tab23[tab23[\"Identification Document Type\"].isin(doc_types)]\n",
    "tab23 = tab23[(tab23['Override Expiry'] == 'Yes') & (tab23['Override Expiry Reason'] != 'Deceased')]\n",
    "\n",
    "tab23_columns = tab23.drop_duplicates(subset=['Party ID'])\n",
    "\n",
    "# state inconsistency type in new column 'Inconsistency'\n",
    "tab23_columns['Inconsistency'] = 'Invalid override expiry reason'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c64a35",
   "metadata": {},
   "source": [
    "### Merge for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f9c3741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# solution 1\n",
    "df_1 = [tab1_columns,tab2_columns,tab3_columns,\n",
    "        tab4_columns,tab5_columns,tab6_columns,\n",
    "        tab7_columns,tab8_columns,tab9_columns,\n",
    "        tab10_columns,tab11_columns,tab11a_columns,\n",
    "        tab21_columns, tab22_columns]\n",
    "\n",
    "result_1 = pd.concat(df_1, join='outer', axis=0)\n",
    "result_1 = result_1.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_1['Beneficiary_role_only']=result_1['Party ID'].isin(bene_only_list)\n",
    "result_1 = result_1[['Party ID','Party Name','RM UID.1','RM Name.1','Date of Birth',\n",
    "                     'Identification Document Type','Identification Document Issue Country',\n",
    "                     'Nationality','Vulnerable Client','Place of Birth', 'Resident pass holder of',\n",
    "                     'Address Type','Address - Country','Identification Document Number',\n",
    "                     'Identification Document Expiry Date','Identification Date of Issue','Inconsistency',\n",
    "                     'Beneficiary_role_only','HK Permanent ID?']]\n",
    "\n",
    "result_1.columns = ['Party ID','Party Name','Party RM UID','Party RM Name','Date of Birth',\n",
    "                    'Identification Document Type','Identification Document Issue Country',\n",
    "                    'Nationality','Vulnerable Client','Place of Birth','Resident pass holder of',\n",
    "                    'Address Type','Address - Country','Identification Document Number',\n",
    "                    'Identification Document Expiry Date','Identification Date of Issue','Inconsistency',\n",
    "                    'Beneficiary_role_only','HK Permanent ID?']\n",
    "\n",
    "# solution 2\n",
    "# output columns\n",
    "result_2 = tab12_columns.sort_values(by=['key','Party Name_pre','Party ID'])\n",
    "result_2['Beneficiary_role_only']=result_2['Party ID'].isin(bene_only_list)\n",
    "result_2 = result_2[['Party ID','Party Name','RM UID.1','RM Name.1',\n",
    "                     'Date of Birth','Identification Document Number',\n",
    "                     'Identification Document Issue Country','Identification Document Type','Inconsistency','Beneficiary_role_only']]\n",
    "# rename columns\n",
    "result_2.columns = ['Party ID','Party Name','Party RM UID','Party RM Name',\n",
    "                    'Date of Birth','Identification Document Number',\n",
    "                    'Identification Document Issue Country','Identification Document Type','Inconsistency','Beneficiary_role_only']\n",
    "\n",
    "\n",
    "# solution 3\n",
    "df_3 = [tab13_columns,tab14_columns,tab15_columns,\n",
    "        tab16_columns,tab17_columns,tab18_columns]\n",
    "\n",
    "result_3 = pd.concat(df_3, join='outer', axis=0)\n",
    "result_3 = result_3.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_3['Beneficiary_role_only']=result_3['Party ID'].isin(bene_only_list)\n",
    "# output columns\n",
    "result_3 = result_3 [['Party ID','Party Name','RM UID.1','RM Name.1',\n",
    "                      'Date of Birth','Identification Document Type',\n",
    "                      'Identification Document Issue Country',\n",
    "                      'Identification Document Number','Identification Date of Issue',\n",
    "                      'Identification Document Expiry Date','Place of Birth',\n",
    "                      'RM UID', 'RM Name','Inconsistency','Beneficiary_role_only']]\n",
    "\n",
    "# rename columns\n",
    "result_3.columns = ['Party ID','Party Name','Party RM UID','Party RM Name',\n",
    "                    'Date of Birth','Identification Document Type',\n",
    "                    'Identification Document Issue Country',\n",
    "                    'Identification Document Number','Identification Date of Issue',\n",
    "                    'Identification Document Expiry Date','Place of Birth',\n",
    "                    'Portfolio RM UID', 'Portfolio RM Name','Inconsistency','Beneficiary_role_only']\n",
    "\n",
    "# solution 4\n",
    "df_4 = [tab19_columns,tab20_columns]\n",
    "result_4 = pd.concat(df_4, join='outer', axis=0)\n",
    "result_4 = result_4.sort_values(by=['Portfolio Name', 'Party Name','Inconsistency'])\n",
    "result_4['Beneficiary_role_only']=result_4['Party ID'].isin(bene_only_list)\n",
    "# output columns\n",
    "result_4 = result_4[['Portfolio Number','Portfolio Name','Party ID',\n",
    "                     'Party Name','Relationship (Party Role)',\n",
    "                     'RM UID.1','RM Name.1','Inconsistency','Beneficiary_role_only']]\n",
    "\n",
    "result_4.columns = ['Portfolio Number','Portfolio Name','Party ID',\n",
    "                    'Party Name','Relationship (Party Role)', \n",
    "                    'Party RM UID', 'Party RM Name','Inconsistency','Beneficiary_role_only']\n",
    "\n",
    "# solution 5\n",
    "df_5 = tab23_columns\n",
    "\n",
    "result_5 = df_5\n",
    "result_5 = result_5.sort_values(by=['Party Name_pre','Inconsistency','Party ID'])\n",
    "result_5['Beneficiary_role_only']=result_5['Party ID'].isin(bene_only_list)\n",
    "# output columns\n",
    "result_5 = result_5[['Party ID', 'Party Name','Date of Birth','Identification Document Type',\n",
    "                     'Identification Document Number','Identification Document Issue Country','Identification Document Expiry Date','Identification Date of Issue',\n",
    "                     'RM UID.1','RM Name.1','Inconsistency',\n",
    "                     'Override Expiry','Override Expiry Reason','Override Expiry Justification',\n",
    "                     'Beneficiary_role_only']] #add ID number, issue date, Expiry Date, country\n",
    "result_5.columns = ['Party ID', 'Party Name','Date of Birth','Identification Document Type',\n",
    "                    'Identification Document Number','Identification Document Issue Country','Identification Document Expiry Date','Identification Date of Issue',\n",
    "                    'Party RM UID','Party RM Name','Inconsistency',\n",
    "                    'Override Expiry','Override Expiry Reason','Override Expiry Justification',\n",
    "                    'Beneficiary_role_only']\n",
    "\n",
    "\n",
    "writer = ExcelWriter(folder_to_save_files, mode='w',date_format = 'yyyy-mm-dd', \n",
    "                        datetime_format='yyyy-mm-dd')\n",
    "\n",
    "result_1.to_excel(writer, 'Same_name_diff_static_info', index=False) #tab1\n",
    "result_2.to_excel(writer, 'Same_ID_diff_name', index=False) #tab2\n",
    "result_3.to_excel(writer, 'incomplete_fields_or_2RM', index=False) #tab3\n",
    "result_4.to_excel(writer, 'AH_BO_mismatch', index=False) #tab4\n",
    "result_5.to_excel(writer, 'Invalid_override_expiry', index=False) #tab5\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a237972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
