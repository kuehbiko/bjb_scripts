{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589421fe",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96238c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b50702",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0de470",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccdba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_report_fold   = \"../CDM Reports/TeamReport1/\" #folder of the team reports\n",
    "user_report_fold   = \"../CDM Reports/UserReport1/\" #folder of the user reports\n",
    "team_task_fold     = \"../CDM Reports/TeamTasks1/\" #folder of the team task report\n",
    "task_history_fold  = \"../CDM Reports/TaskHistory1/\" #folder of the team task report\n",
    "jasper_report_fold = \"../CDM Reports/JasperReport1/\" #folder of the jasper report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = [team_report_fold, user_report_fold, team_task_fold, task_history_fold, jasper_report_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944374f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "# for each folder, walk through all directories and subdirectories\n",
    "final_dfs = []\n",
    "for folder in folder_list:\n",
    "    temp_dfs = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.xlsx'): # check if the file is an excel file\n",
    "                # read the file into a data frame and append it to the list of data frames\n",
    "                df = pd.read_excel(os.path.join(root, file))\n",
    "                temp_dfs.append(df)\n",
    "\n",
    "    # concat all data frames into a single data frame\n",
    "    df = pd.concat(temp_dfs, ignore_index=True)\n",
    "    final_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_report_df   = final_dfs[0]\n",
    "user_report_df   = final_dfs[1]\n",
    "team_tasks_df    = final_dfs[2]\n",
    "task_history_df  = final_dfs[3]\n",
    "jasper_report_df = final_dfs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_df = pd.read_excel(\"Data.xlsx\", sheet_name=\"Base\")\n",
    "bc_list_df = pd.read_excel(\"Data.xlsx\",sheet_name=\"Bulk Creation\")\n",
    "gv_list_df = pd.read_excel(\"Data.xlsx\",sheet_name=\"Generic Volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324193e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ab4cc",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2123bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with no case number and no process type and no task ID\n",
    "team_report_df = team_report_df.dropna(axis=0, subset=[\"Task ID\", \"Case No\", \"Process Type\"])\n",
    "user_report_df = user_report_df.dropna(axis=0, subset=[\"Task ID\", \"Case No\", \"Process Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26892a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select rows with process type == \"SG - ...\"\n",
    "team_report_df = team_report_df[team_report_df[\"Process Type\"].str.contains(\"SG - \")]\n",
    "user_report_df = user_report_df[user_report_df[\"Process Type\"].str.contains(\"SG - \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip all trailing whitespace:\n",
    "'''team_report_df = team_report_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "user_report_df = user_report_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "team_tasks_df = team_tasks_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "dashboard_df = dashboard_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "bc_list_df = bc_list_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "gv_list_df = gv_list_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove cases that also appear in the Team Task Report (cases that are still open)\n",
    "team_report_df = team_report_df[~team_report_df[\"Case No\"].isin(team_tasks_df[\"Case No\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5730ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date cells to datetime object type\n",
    "team_report_df[\"Task Closure Date\"] = pd.to_datetime(team_report_df[\"Task Closure Date\"])\n",
    "team_report_df[\"Task Assigned to Date\"] = pd.to_datetime(team_report_df[\"Task Assigned to Date\"])\n",
    "user_report_df[\"Task Assigned to Date\"] = pd.to_datetime(user_report_df[\"Task Assigned to Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of teams and processes used for dashboard\n",
    "process_list = dashboard_df[\"Process Type\"].tolist()\n",
    "team_list = dashboard_df[\"Team\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exceptions for bulk creation and generic volume\n",
    "bc_list = bc_list_df.to_numpy().tolist()\n",
    "gv_list = gv_list_df.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c720b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e29af1",
   "metadata": {},
   "source": [
    "### Data Cleaning: Dates - Part 1 (Remove Weekends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort ascending according to Case No, Task ID, Task Assigned to Date, Time taken (in days) aggregated\n",
    "team_report_df = team_report_df.sort_values([\"Case No\", \"Task ID\", \"Task Assigned to Date\", \"Time taken (in days) aggregated\"])\n",
    "user_report_df = user_report_df.sort_values([\"Case No\", \"Task ID\", \"Task Assigned to Date\", \"Actual Time Taken\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize into a list of cases, and list of tasks ordered by the respective cases\n",
    "case_list = pd.unique(team_report_df[\"Case No\"]).tolist()\n",
    "task_list_temp = []\n",
    "for case in case_list:\n",
    "    temp_df = team_report_df[team_report_df[\"Case No\"]==case]\n",
    "    task_list_temp.append(pd.unique(temp_df[\"Task ID\"]).tolist())\n",
    "task_list = [item for sublist in task_list_temp for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalculating the number of days taken - excluding weekends. to be in line with CDM logic, public holidays will not be excluded\n",
    "new_time_taken_temp = []\n",
    "calendar_days_temp = []\n",
    "for task in task_list:\n",
    "    #get list of all dates in \"Task Assigned to Date\" for ONE task, sorted\n",
    "    temp_df = team_report_df[team_report_df[\"Task ID\"]==task]\n",
    "    #create a list of the dates (in chronological order) where tasks are assigned to teams\n",
    "    assigned_dates = pd.to_datetime(temp_df[\"Task Assigned to Date\"]).tolist()\n",
    "    #add task closure date to end of list\n",
    "    closure_date = list(set(pd.to_datetime(temp_df[\"Task Closure Date\"]).tolist()))\n",
    "    assigned_dates.append(closure_date[0])\n",
    "    \n",
    "    #find difference between adjacent dates in the list (1. diff by business days, 2. diff by calendar days)\n",
    "    new_time_taken_temp.append([np.busday_count(j.date(), i.date()) for i,j in zip(assigned_dates[1:], assigned_dates[:-1])])\n",
    "    calendar_days_temp.append([(i.date() - j.date()).days for i,j in zip(assigned_dates[1:], assigned_dates[:-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for new re-calculated time taken that excludes weekends and phs\n",
    "#flatten the temp lists so i can convert them into columns\n",
    "new_time_taken = [item for sublist in new_time_taken_temp for item in sublist]\n",
    "calendar_days = [item for sublist in calendar_days_temp for item in sublist]\n",
    "team_report_df[\"New Time Taken\"] = new_time_taken\n",
    "team_report_df[\"Calendar Days\"] = calendar_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bddf23",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db026457",
   "metadata": {},
   "source": [
    "### Data Cleaning: Dates - Part 2 (Tasks Pending With)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfb04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is where- we cross-reference with the user report\n",
    "#flag out the tasks where calendar days ! = time taken aggregate (means that tasks were reassigned out at some point)\n",
    "assigned_out_df = team_report_df[team_report_df[\"Time taken (in days) aggregated\"] != team_report_df[\"Calendar Days\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea796f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare to user report to get the accurate time taken\n",
    "#get list of all the flagged tasks\n",
    "assigned_out_task_list = pd.unique(assigned_out_df[\"Task ID\"]).tolist()\n",
    "#create a new list for storage\n",
    "new_user_time_taken_temp = []\n",
    "\n",
    "#loop through tasks in the flagged task list \n",
    "for task in assigned_out_task_list:\n",
    "    temp_df = team_report_df[team_report_df[\"Task ID\"]==task]\n",
    "    temp_user_df = user_report_df[user_report_df[\"Task ID\"]==task]\n",
    "\n",
    "    #this should create a list of all the dates where the tasks were reassigned + closure date (in chronological order)\n",
    "    assigned_user_dates = pd.to_datetime(temp_user_df[\"Task Assigned to Date\"]).tolist()\n",
    "    closure_date = list(set(pd.to_datetime(temp_df[\"Task Closure Date\"]).tolist()))\n",
    "    assigned_user_dates.append(closure_date[0])\n",
    "    \n",
    "    #find difference between adjacent dates in the list\n",
    "    new_user_time_taken_temp.append([np.busday_count(j.date(), i.date()) for i,j in zip(assigned_user_dates[1:], assigned_user_dates[:-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_time_taken = [item for sublist in new_user_time_taken_temp for item in sublist] #this list is too long. where are the extra values coming from\n",
    "#match back to user report since calculations were made with user report data\n",
    "user_report_df1 = user_report_df[user_report_df[\"Task ID\"].isin(assigned_out_task_list)]\n",
    "user_report_df1[\"Time Taken (User Report)\"] = new_user_time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of the total time (.sum()) taken per task per team, based on the user report. store in time_list\n",
    "time_list = []\n",
    "for task, team in zip(assigned_out_df[\"Task ID\"],assigned_out_df[\"Team\"]):\n",
    "    #time taken, in business days, based on user report\n",
    "    x = user_report_df1[(user_report_df1[\"Task ID\"]==task) & (user_report_df1[\"Team\"]==team)][\"Time Taken (User Report)\"].sum()\n",
    "    time_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"New Time Taken\" for flagged tasks are immediately replaced with the Time Taken based on the User Report\n",
    "assigned_out_df[\"New Time Taken\"] = time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge team_report_closed_df and assigned_out_df back together\n",
    "#1. remove the rows from team_report_closed_df that correspond to assigned_out_df\n",
    "#2. append/concat the full assigned_out_df dataframe to team_report_closed_df\n",
    "\n",
    "to_drop = assigned_out_df.index.values.tolist()\n",
    "team_report_df = team_report_df.drop(to_drop)\n",
    "team_report_df = pd.concat([team_report_df, assigned_out_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the part where we take the minimum of the new time taken and the time taken aggregate to account for tasks that were assigned out to Front/IT/etc.\n",
    "team_report_df[\"Min Time Taken\"] = team_report_df[[\"New Time Taken\",\"Time taken (in days) aggregated\"]].min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be01bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93072e3",
   "metadata": {},
   "source": [
    "### Team Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d633f7c",
   "metadata": {},
   "source": [
    "#### Bulk Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a23c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk creation: creating dataframe\n",
    "bulk_creation_df = pd.DataFrame()\n",
    "for idx in range(len(bc_list)):    \n",
    "    temp_df = team_report_df[(team_report_df[\"Team\"]==bc_list[idx][0]) &\n",
    "                             (team_report_df[\"Process Type\"]==bc_list[idx][1]) &\n",
    "                             (team_report_df[\"Task Type\"]==bc_list[idx][2])]\n",
    "    bulk_creation_df = pd.concat([bulk_creation_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfbe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column to indicate if task is overdue\n",
    "bulk_creation_df['days_overdue'] = bulk_creation_df[\"Team Defined SLA (in days)\"] - bulk_creation_df[\"Min Time Taken\"]\n",
    "\n",
    "# create new column to indicate bulk creation volume count for each case\n",
    "bulk_creation_df['total_volume'] = 1\n",
    "for case_no in bulk_creation_df['Case No'].tolist():\n",
    "    vol = bulk_creation_df[bulk_creation_df['Case No']==case_no]['Task ID'].nunique()\n",
    "    bulk_creation_df.loc[bulk_creation_df['Case No']==case_no,'total_volume'] = vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628eb83",
   "metadata": {},
   "source": [
    "#### Generic Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86975ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: creating dataframe\n",
    "generic_volume_df = pd.DataFrame()\n",
    "for idx in range(len(gv_list)):\n",
    "    temp_df = team_report_df[(team_report_df[\"Team\"]==gv_list[idx][0]) &\n",
    "                             (team_report_df[\"Process Type\"]==gv_list[idx][1]) &\n",
    "                             (team_report_df[\"Task Type\"]==gv_list[idx][2])]\n",
    "    generic_volume_df = pd.concat([generic_volume_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: preprocessing. fill all blank cells, convert each cell to list and take the last element of the list\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].fillna('1')\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].astype(str) #necessary step in the case where all generic volume entries are miraculously somehow all integers\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].apply(lambda x: list(x.split(\",\"))[-1]) #last entry of generic volume is the latest input in CDM task\n",
    "generic_volume_df[\"Generic Volume\"] = (generic_volume_df[\"Generic Volume\"].astype(float)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column to indicate if task is overdue\n",
    "generic_volume_df['days_overdue'] = generic_volume_df[\"Team Defined SLA (in days)\"] - generic_volume_df[\"Min Time Taken\"]\n",
    "\n",
    "# create new column to indicate bulk creation volume count for each case\n",
    "generic_volume_df['total_volume'] = 1\n",
    "for case_no in generic_volume_df['Case No'].tolist():\n",
    "    vol = generic_volume_df[generic_volume_df['Case No']==case_no]['Generic Volume'].max()\n",
    "    if vol == 0: vol=1\n",
    "    generic_volume_df.loc[generic_volume_df['Case No']==case_no,'total_volume'] = vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f3c5c",
   "metadata": {},
   "source": [
    "#### Case Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case volume: creating remaining dataframe\n",
    "case_volume_df = team_report_df.drop(generic_volume_df.index, errors='ignore')\n",
    "case_volume_df = case_volume_df.drop(bulk_creation_df.index, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just mark which cases are past SLA and which arent\n",
    "case_volume_df['days_overdue'] = case_volume_df[\"Team Defined SLA (in days)\"] - case_volume_df[\"Min Time Taken\"]\n",
    "\n",
    "# create new column to indicate case volume count for each case\n",
    "case_volume_df['total_volume'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a13e0",
   "metadata": {},
   "source": [
    "#### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f6f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all 3 vol dfs together\n",
    "team_report_final_df = pd.concat([bulk_creation_df, generic_volume_df, case_volume_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ac69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for final volume (take max volume per case)\n",
    "team_report_final_df['final_volume'] = 1\n",
    "for case_no in team_report_final_df['Case No'].tolist():\n",
    "    vol = team_report_final_df[team_report_final_df['Case No']==case_no]['total_volume'].max()\n",
    "    team_report_final_df.loc[team_report_final_df['Case No']==case_no,'final_volume'] = vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column to indicate if a task is overdue\n",
    "team_report_final_df['overdue'] = team_report_final_df['days_overdue'].apply(lambda x: 'Yes' if x<0 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert portfolios to list\n",
    "team_report_final_df[\"Portfolio Number\"] = team_report_final_df[\"Portfolio Number\"].fillna('0')\n",
    "team_report_final_df[\"Portfolio Number\"] = team_report_final_df[\"Portfolio Number\"].apply(lambda x: list(x.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_report_final_df = team_report_final_df.explode(\"Portfolio Number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c6f69",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38755e43",
   "metadata": {},
   "source": [
    "### User Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by case number\n",
    "#user_report_df['time_taken'] = 0\n",
    "#for case_no in user_report_df['Case No'].tolist():\n",
    "#    time = user_report_df[user_report_df['Case No']==case_no]['Actual Time Taken'].max()\n",
    "#    user_report_df.loc[user_report_df['Case No']==case_no,'time_taken'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08045717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate time taken into bins\n",
    "user_report_df['Bin_0-3'] = user_report_df['Actual Time Taken'].apply(lambda x: 1 if x<4 else 0)\n",
    "user_report_df['Bin_4-6'] = user_report_df['Actual Time Taken'].apply(lambda x: 1 if (x>3 and x<7) else 0)\n",
    "user_report_df['Bin_7-8'] = user_report_df['Actual Time Taken'].apply(lambda x: 1 if (x>6 and x<9) else 0)\n",
    "user_report_df['Bin_9+'] = user_report_df['Actual Time Taken'].apply(lambda x: 1 if x>8 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f401b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c263e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_report_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686ea57",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f513f",
   "metadata": {},
   "source": [
    "### Task History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert portfolios to list (task history - for rejection reason)\n",
    "task_history_df[\"Portfolio\"] = task_history_df[\"Portfolio\"].fillna('0')\n",
    "task_history_df[\"Portfolio\"] = task_history_df[\"Portfolio\"].apply(lambda x: list(x.split(\",\")))\n",
    "task_history_df = task_history_df.explode(\"Portfolio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80613ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert portfolios to list (task history - for rejection reason)\n",
    "task_history_df[\"Assigned To Team\"] = task_history_df[\"Assigned To Team\"].fillna('0')\n",
    "task_history_df[\"Assigned To Team\"] = task_history_df[\"Assigned To Team\"].apply(lambda x: list(x.split(\" ; \")))\n",
    "task_history_df = task_history_df.explode(\"Assigned To Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rejection reasons to list (task history - for rejection reason)\n",
    "task_history_df[\"Rejection Reason\"] = task_history_df[\"Rejection Reason\"].fillna('0')\n",
    "task_history_df[\"Rejection Reason\"] = task_history_df[\"Rejection Reason\"].apply(lambda x: list(x.split(\",\")))\n",
    "task_history_df = task_history_df.explode(\"Rejection Reason\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1dc419",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fccf289",
   "metadata": {},
   "source": [
    "### Merge Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691072a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the dataframes\n",
    "# merge with jasper report\n",
    "merged_df1 = team_report_final_df.merge(jasper_report_df, how='inner', on='Portfolio Number', suffixes=('_tr', '_jr'))\n",
    "# merge with user report\n",
    "#merged_df1 = merged_df1.merge(user_report_df, how='inner', on='')\n",
    "# merge with task history report\n",
    "#merged_df1 = merged_df1.merge(task_history_df, how='inner', on='Task ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2 = task_history_df.merge(jasper_report_df, how='outer', left_on='Portfolio', right_on='Portfolio Number', suffixes=('_th', '_jp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fb15e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8430e",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d2fc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_df1.to_excel(\"../Output/tr-jr_merged.xlsx\", index=False)\n",
    "merged_df2.to_excel(\"../Output/th-jr_merged.xlsx\", index=False)\n",
    "user_report_df.to_excel(\"../Output/user_report.xlsx\", index=False)\n",
    "print(\"Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
