{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"TeamTasks\" \n",
    "report_date = input(\"report date (DD MMM YYYY): \") #date that report was extracted 02 Apr 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85f140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "team_tasks_pending_df = pd.read_excel(\"../CDM Reports/\" + filename + \".xlsx\", \n",
    "                                      usecols=[\"Task ID\",\n",
    "                                               \"Task Type\",\n",
    "                                               \"Case No\",\n",
    "                                               \"Process Type\",\n",
    "                                               \"Status\",\n",
    "                                               \"Last Assigned To Team\",\n",
    "                                               \"Last Assigned Date\",\n",
    "                                               \"Task Pending With\",\n",
    "                                               \"Generic Volume\"])\n",
    "dashboard_df = pd.read_excel(\"Data.xlsx\", sheet_name=\"Base\")\n",
    "bc_list_df = pd.read_excel(\"Data.xlsx\", sheet_name=\"Bulk Creation\")\n",
    "gv_list_df = pd.read_excel(\"Data.xlsx\", sheet_name=\"Generic Volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a3cab",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with no case number or with no process type and no task ID\n",
    "team_tasks_pending_df = team_tasks_pending_df.dropna(axis=0, subset=[\"Task ID\", \"Case No\", \"Process Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select rows with only SG process types --> process type starts with \"SG - ...\"\n",
    "team_tasks_pending_df = team_tasks_pending_df[team_tasks_pending_df[\"Process Type\"].str.contains(\"SG - \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip all trailing whitespace:\n",
    "team_tasks_pending_df = team_tasks_pending_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ea4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to datetime\n",
    "team_tasks_pending_df[\"Last Assigned Date\"] = pd.to_datetime(team_tasks_pending_df[\"Last Assigned Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4208f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for new due date. public holiday will not be excluded to be more in line with the CDM logic\n",
    "last_assigned_date = team_tasks_pending_df[\"Last Assigned Date\"].tolist()\n",
    "#match dashboard SLA to the team-task combinations in raw data using left JOIN\n",
    "team_tasks_pending_df = pd.merge(team_tasks_pending_df, dashboard_df,\n",
    "                                 how='left', \n",
    "                                 left_on=[\"Process Type\",\"Last Assigned To Team\"], \n",
    "                                 right_on = [\"Process Type\",\"Team\"])\n",
    "team_SLA = team_tasks_pending_df[\"Defined SLA (days)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate new due date\n",
    "def date_by_adding_business_days(from_date, add_days): #https://stackoverflow.com/questions/12691551\n",
    "    business_days_to_add = add_days\n",
    "    new_date = from_date\n",
    "    while business_days_to_add > 0:\n",
    "        new_date += timedelta(days=1)\n",
    "        weekday = new_date.weekday()\n",
    "        if weekday >= 5: continue # 5:saturday, 6:sunday\n",
    "        business_days_to_add -= 1\n",
    "    return new_date\n",
    "\n",
    "new_due_date = []\n",
    "for idx,val in enumerate(last_assigned_date):\n",
    "    from_date = val\n",
    "    add_days = team_SLA[idx]\n",
    "    new_due_date.append(date_by_adding_business_days(from_date, add_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for new due dates and drop rows where process-team did not match\n",
    "team_tasks_pending_df[\"New Due Date\"] = new_due_date\n",
    "team_tasks_pending_df = team_tasks_pending_df.dropna(axis=0, subset=[\"Team\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56891af",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420156d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select only cases exceeding SLA: due date earlier(<) than report date\n",
    "#if due date == report date, task is NOT overdue\n",
    "report_datetime = datetime.strptime(report_date, \"%d %b %Y\")\n",
    "team_tasks_pending_df = team_tasks_pending_df[team_tasks_pending_df[\"New Due Date\"] < report_datetime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a083aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number of days for which the task is overdue\n",
    "temp = list(pd.to_datetime(team_tasks_pending_df[\"New Due Date\"]))\n",
    "new_due_date_list = [i.to_pydatetime() for i in temp]\n",
    "team_tasks_pending_df[\"Days Overdue\"] = [np.busday_count(i.date(), report_datetime.date()) for i in new_due_date_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77bf99",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of all distinct cases\n",
    "distinct_cases = pd.unique(team_tasks_pending_df[\"Case No\"]).tolist()\n",
    "case_task_dict = {case: pd.unique(team_tasks_pending_df[team_tasks_pending_df[\"Case No\"]==case][\"Task ID\"]).tolist() for case in distinct_cases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all cases and corresponding teams\n",
    "pending_with_1 = []\n",
    "pending_with_1_df = pd.DataFrame()\n",
    "pending_with_many = []\n",
    "pending_with_many_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109da781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate cases if they are in 1/more than 1 team's queue\n",
    "for case in case_task_dict.keys():\n",
    "    temp_df = team_tasks_pending_df[team_tasks_pending_df[\"Case No\"]==case]\n",
    "    set_of_teams = {team for team in temp_df['Last Assigned To Team'].unique()}    \n",
    "    if len(set_of_teams) == 1: pending_with_1.append(case)\n",
    "    else: pending_with_many.append([case, set_of_teams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store all tasks associated with each list in dataframe\n",
    "#pending_with_1 used for further analysis, pending_with_many to give to line managers\n",
    "pending_with_1_df = pd.DataFrame()\n",
    "pending_with_many_df = pd.DataFrame()\n",
    "for case in pending_with_1:\n",
    "    temp_df = team_tasks_pending_df[team_tasks_pending_df[\"Case No\"]==case]\n",
    "    pending_with_1_df = pd.concat([pending_with_1_df, temp_df], ignore_index=True)\n",
    "for case in pending_with_many_df:\n",
    "    temp_df = team_tasks_pending_df[team_tasks_pending_df[\"Case No\"]==case]\n",
    "    pending_with_many_df = pd.concat([pending_with_many_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f6f787",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove cases pending with other departments\n",
    "#temp_df = pending_with_1_df.dropna(axis=0, subset=[\"Task Pending With\"])\n",
    "#task_pending_with = temp_df[\"Case No\"].unique().tolist() #list of cases pending that are pending with other departments\n",
    "#pending_with_1_df = pending_with_1_df[~pending_with_1_df[\"Case No\"].isin(task_pending_with)] #remove rows containing cases that are in task_pending_with list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a25fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of cases (and respective teams) that are pending with other departments\n",
    "#instead of case number only, we should do [case, team] instead\n",
    "#that way we can remove cases based on associated teams\n",
    "\n",
    "\n",
    "#if i separate the tasks into pending with 1/pending with many BEFORE i remove cases, this will remove this problem?\n",
    "#because if the case is marked as Pending With by 1 team and not marked as Pending With by another team, \n",
    "#then it is in 2 team queues and that should not be the case already.\n",
    "\n",
    "#therefore this is a non-issue. just need to re-order my code.\n",
    "\n",
    "#in order of importance?:\n",
    "#1. task pending with multiple ACM teams\n",
    "#2. task pending with other departments\n",
    "#unless it does not count as pending with multiple ACM teams if it is not Pending With other departments for only 1 team\n",
    "#eg. does not count as pending with multiple ACM teams if STATIC has marked it as Pending With Front but CAM has not\n",
    "#in this case it would count as pending with CAM only?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0264844",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of process types, teams\n",
    "process_type_input = dashboard_df[\"Process Type\"].tolist()\n",
    "team_input = dashboard_df[\"Team\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd70df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exceptions to list\n",
    "bc_list = bc_list_df.to_numpy().tolist() #bulk creation\n",
    "gv_list = gv_list_df.to_numpy().tolist() #generic volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59213f9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk creation: creating dataframe\n",
    "bulk_creation_df = pd.DataFrame()\n",
    "for idx in range(len(bc_list)):    \n",
    "    temp_df = pending_with_1_df[(pending_with_1_df[\"Last Assigned To Team\"]==bc_list[idx][0]) &\n",
    "                                (pending_with_1_df[\"Process Type\"]==bc_list[idx][1]) &\n",
    "                                (pending_with_1_df[\"Task Type\"]==bc_list[idx][2])]\n",
    "    bulk_creation_df = pd.concat([bulk_creation_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk creation: counting volume\n",
    "bc_pending_data = []\n",
    "bc_pending_list = []\n",
    "for idx in range(len(process_type_input)):\n",
    "    #pending bulk creation tasks\n",
    "    bc_pending_df = bulk_creation_df[(bulk_creation_df[\"Process Type\"]==process_type_input[idx]) &\n",
    "                                     (bulk_creation_df[\"Last Assigned To Team\"]==team_input[idx]) &\n",
    "                                     (bulk_creation_df[\"Task Pending With\"].isna())] #select tasks which are not pending with other departments on a team by team basis\n",
    "    #bc_pending_data.append(len(pd.unique(bc_pending_df[\"Task ID\"])))\n",
    "    \n",
    "    temp_dict = {}\n",
    "    for case in list(pd.unique(bc_pending_df[\"Case No\"])): #for each case, get list of unique task types\n",
    "        unique_tasktype_list = list(pd.unique(bc_pending_df[bc_pending_df[\"Case No\"]==case][\"Task Type\"]))\n",
    "        \n",
    "        bc_volume_by_task = []\n",
    "        for tasktype in unique_tasktype_list: #for each task type within case, calculate bulk creation volume: (len(unique(task IDs)))\n",
    "            bc_volume_by_task.append(len(pd.unique(bc_pending_df[(bc_pending_df[\"Case No\"]==case) & (bc_pending_df[\"Task Type\"]==tasktype)][\"Task ID\"])))\n",
    "        \n",
    "        bc_volume_by_case = max(bc_volume_by_task) #bc volume for each case is max(volume of task type 1, volume of task type 2) )\n",
    "        #temp_list.append([case, bc_volume_by_case]) #append to temp_list [(case1, volume), (case2, volume), (case3, volume), etc.]\n",
    "        temp_dict[case] = bc_volume_by_case\n",
    "        \n",
    "    bc_pending_data.append(temp_dict) #append to bc_completed_data [temp_list for Process1TeamA, temp_list for Process2TeamA, etc.]\n",
    "    \n",
    "    bc_pending_list.append(list(pd.unique(bc_pending_df[\"Case No\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33f245",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: creating dataframe\n",
    "generic_volume_df = pd.DataFrame()\n",
    "for idx in range(len(gv_list)):\n",
    "    temp_df = pending_with_1_df[(pending_with_1_df[\"Team\"]==gv_list[idx][0]) &\n",
    "                                (pending_with_1_df[\"Process Type\"]==gv_list[idx][1]) &\n",
    "                                (pending_with_1_df[\"Task Type\"]==gv_list[idx][2])]\n",
    "    generic_volume_df = pd.concat([generic_volume_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: preprocessing. fill all blank cells, convert each cell to list and take the last element of the list\n",
    "#last entry of generic volume is the latest input in CDM task\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].fillna('1')\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].astype(str) #necessary step in the case where all generic volume entries are miraculously somehow all integers\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].apply(lambda x: list(x.split(\",\"))[-1])\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: counting volume\n",
    "gv_pending_data = []\n",
    "gv_pending_list = []\n",
    "for idx in range(len(process_type_input)):\n",
    "    #pending generic volume tasks\n",
    "    gv_pending_df = generic_volume_df[(generic_volume_df[\"Process Type\"]==process_type_input[idx]) &\n",
    "                                      (generic_volume_df[\"Last Assigned To Team\"]==team_input[idx]) &\n",
    "                                      (generic_volume_df[\"Task Pending With\"].isna())] #select tasks which are not pending with other departments on a team by team basis \n",
    "    #if gv_pending_df[\"Generic Volume\"].max() == 0: gv_count = 1\n",
    "    #else: gv_count = gv_pending_df[\"Generic Volume\"].max()\n",
    "    #gv_pending_data.append(gv_count)\n",
    "    \n",
    "    temp_dict = {}\n",
    "    for case in list(pd.unique(gv_pending_df[\"Case No\"])): #for each case\n",
    "        temp_df = gv_pending_df[gv_pending_df[\"Case No\"]==case] #filtered by case ONLY\n",
    "        #counting generic volume by CASE\n",
    "        if temp_df[\"Generic Volume\"].max() == 0: gv_pending_count = 1 \n",
    "        else: gv_pending_count = temp_df[\"Generic Volume\"].max()\n",
    "        #temp_list.append([case, gv_completed_count]) #list of volume by case eg. [[case1,1], [case2,3], [case3,4]]\n",
    "        temp_dict[case] = gv_pending_count\n",
    "        \n",
    "    gv_pending_data.append(temp_dict) #temp_list for each process/team eg. [temp_list of process1teamA, temp_list of process1teamB, etc.]\n",
    "    \n",
    "    gv_pending_list.append(list(pd.unique(gv_pending_df[\"Case No\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ff61c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f154ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case volume: creating remaining dataframe\n",
    "case_volume_df = pending_with_1_df.drop(bulk_creation_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecf687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case volume: counting volume\n",
    "case_pending_data = []\n",
    "case_pending_list = []\n",
    "for idx in range(len(process_type_input)):\n",
    "    case_pending_df = case_volume_df[(case_volume_df[\"Process Type\"]==process_type_input[idx]) &\n",
    "                                     (case_volume_df[\"Last Assigned To Team\"]==team_input[idx]) &\n",
    "                                     (case_volume_df[\"Task Pending With\"].isna())] #select tasks which are not pending with other departments on a team by team basis\n",
    "    \n",
    "    pending_case_list = list(pd.unique(case_pending_df[\"Case No\"]))\n",
    "    #list compre makes a list of [[case1,1],[case2,1],etc.]. case vol is always 1.\n",
    "    #case_completed_data.append([[case_list[i],1] for i in range(len(completed_case_list))]) \n",
    "    case_pending_data.append({pending_case_list[pending_case_list.index(i)]:1 for i in pending_case_list})\n",
    "    \n",
    "    #print(process_type_input[idx], team_input[idx], {pending_case_list[pending_case_list.index(i)]:1 for i in pending_case_list})\n",
    "    \n",
    "    #case_pending_data.append(len(pd.unique(case_pending_df[\"Case No\"])))\n",
    "    case_pending_list.append(list(pd.unique(case_pending_df[\"Case No\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f483cb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate median days overdue per process per Team\n",
    "median_overdue_data = []\n",
    "for idx in range(len(process_type_input)):\n",
    "    #data for calculating median per processtype/team\n",
    "    median_overdue_df = pending_with_1_df[(pending_with_1_df[\"Process Type\"]==process_type_input[idx]) &\n",
    "                                          (pending_with_1_df[\"Last Assigned To Team\"]==team_input[idx]) &\n",
    "                                          (pending_with_1_df[\"Task Pending With\"].isna())] #select tasks which are not pending with other departments on a team by team basis\n",
    "    #take max time taken (among all tasks per process per team) for each case\n",
    "    #for case in pd.unique(median_overdue_df[\"Case No\"]):\n",
    "        #median_overdue_df[\"Days Overdue\"] = median_overdue_df[median_overdue_df[\"Case No\"]==case][\"Days Overdue\"].max()\n",
    "    #median_overdue_df = median_overdue_df.drop_duplicates(subset=\"Case No\")\n",
    "    #median_overdue_data.append(median_overdue_df[\"Days Overdue\"].median())\n",
    "    \n",
    "    df = median_overdue_df.groupby(by='Case No')[['Days Overdue']].max().reset_index()\n",
    "    median_overdue_data.append(df['Days Overdue'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa601c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c11b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_data = []\n",
    "for i in range(len(bc_pending_data)): #to loop through the list. each list is the same length, bc_completed pick arbitrarily\n",
    "    case_list = list(bc_pending_data[i].keys()) + list(gv_pending_data[i].keys()) + list(case_pending_data[i].keys())\n",
    "    case_set = set(case_list)\n",
    "    x = 0\n",
    "    for j in case_set:\n",
    "        templist = [bc_pending_data[i].get(j), gv_pending_data[i].get(j), case_pending_data[i].get(j)]\n",
    "        temparray = np.array(templist, dtype=np.float64)\n",
    "        x += np.nanmax(temparray)\n",
    "    pending_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine pending volume count\n",
    "pending_list = [\", \".join(set(i+j+k)) for i,j,k in zip(bc_pending_list, gv_pending_list, case_pending_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81d1b5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zip(process_type_input,team_input,pending_data,median_overdue_data,pending_list)\n",
    "output_df = pd.DataFrame(data, columns=[\"Process Type\",\n",
    "                                        \"Team\",\n",
    "                                        \"Total Volume (backlog)\",\n",
    "                                        \"Median Days Overdue\",\n",
    "                                        \"Pending Cases\"])\n",
    "output_df = output_df.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad94a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv(\"../Output/PendingCases.csv\", index=False)\n",
    "#pending_with_many - want to output this in a way that lists the teams involved right?\n",
    "print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
