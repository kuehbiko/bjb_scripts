{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96238c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccdba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_report_filename = \"TeamReport\" \n",
    "user_report_filename = \"UserReport\" \n",
    "team_task_report_filename = \"TeamTasks\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "team_report_closed_df = pd.read_excel(\"../CDM Reports/\" + team_report_filename + \".xlsx\",\n",
    "                                      usecols=[\"Task ID\",\n",
    "                                               \"Task Type\",\n",
    "                                               \"Process Type\",\n",
    "                                               \"Case No\",\n",
    "                                               \"Task Closure Date\",\n",
    "                                               \"Currrent Task Status\",\n",
    "                                               \"Task Assigned to Date\",\n",
    "                                               \"Team\",\n",
    "                                               \"Team Defined SLA (in days)\",\n",
    "                                               \"Time taken (in days) aggregated\",\n",
    "                                               \"Generic Volume\"])\n",
    "user_report_df = pd.read_excel(\"../CDM Reports/\" + user_report_filename + \".xlsx\",\n",
    "                               usecols=[\"Case No\",\n",
    "                                        \"Task ID\",\n",
    "                                        \"Process Type\",\n",
    "                                        \"Currrent Task Status\",\n",
    "                                        \"User\",\n",
    "                                        \"Task Assigned to Date\",\n",
    "                                        \"Team\",\n",
    "                                        \"Actual Time Taken\"])\n",
    "team_task_report_df = pd.read_excel(\"../CDM Reports/\" + team_task_report_filename + \".xlsx\",\n",
    "                                    usecols=[\"Case No\"])\n",
    "dashboard_df = pd.read_excel(\"Data.xlsx\", sheet_name=\"Base\")\n",
    "bc_list_df = pd.read_excel(\"Data.xlsx\",sheet_name=\"Bulk Creation\")\n",
    "gv_list_df = pd.read_excel(\"Data.xlsx\",sheet_name=\"Generic Volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324193e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2123bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with no case number and no process type and no task ID\n",
    "team_report_closed_df = team_report_closed_df.dropna(axis=0, subset=[\"Task ID\", \"Case No\", \"Process Type\"])\n",
    "user_report_df = user_report_df.dropna(axis=0, subset=[\"Task ID\", \"Case No\", \"Process Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26892a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select rows with process type == \"SG - ...\"\n",
    "team_report_closed_df = team_report_closed_df[team_report_closed_df[\"Process Type\"].str.contains(\"SG - \")]\n",
    "user_report_df = user_report_df[user_report_df[\"Process Type\"].str.contains(\"SG - \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad194421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select rows for completed/rejected tasks only\n",
    "team_report_closed_df = team_report_closed_df[(team_report_closed_df[\"Currrent Task Status\"]==\"COMPLETED\") |\n",
    "                                              (team_report_closed_df[\"Currrent Task Status\"]==\"REJECTED\")]\n",
    "user_report_df = user_report_df[(user_report_df[\"Currrent Task Status\"]==\"COMPLETED\") |\n",
    "                                (user_report_df[\"Currrent Task Status\"]==\"REJECTED\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip all trailing whitespace:\n",
    "team_report_closed_df = team_report_closed_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "user_report_df = user_report_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "team_task_report_df = team_task_report_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "dashboard_df = dashboard_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "bc_list_df = bc_list_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "gv_list_df = gv_list_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove cases that also appear in the Team Task Report (cases that are still open)\n",
    "team_report_closed_df = team_report_closed_df[~team_report_closed_df[\"Case No\"].isin(team_task_report_df[\"Case No\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5730ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date cells to datetime object type\n",
    "team_report_closed_df[\"Task Closure Date\"] = pd.to_datetime(team_report_closed_df[\"Task Closure Date\"])\n",
    "team_report_closed_df[\"Task Assigned to Date\"] = pd.to_datetime(team_report_closed_df[\"Task Assigned to Date\"])\n",
    "user_report_df[\"Task Assigned to Date\"] = pd.to_datetime(user_report_df[\"Task Assigned to Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of teams and processes used for dashboard\n",
    "process_list = dashboard_df[\"Process Type\"].tolist()\n",
    "team_list = dashboard_df[\"Team\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exceptions for bulk creation and generic volume\n",
    "bc_list = bc_list_df.to_numpy().tolist()\n",
    "gv_list = gv_list_df.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c720b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort ascending according to Case No, Task ID, Task Assigned to Date, Time taken (in days) aggregated\n",
    "team_report_closed_df = team_report_closed_df.sort_values([\"Case No\", \n",
    "                                                           \"Task ID\", \n",
    "                                                           \"Task Assigned to Date\", \n",
    "                                                           \"Time taken (in days) aggregated\"])\n",
    "user_report_df = user_report_df.sort_values([\"Case No\", \n",
    "                                             \"Task ID\", \n",
    "                                             \"Task Assigned to Date\", \n",
    "                                             \"Actual Time Taken\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize into a list of cases, and list of tasks ordered by the respective cases\n",
    "case_list = pd.unique(team_report_closed_df[\"Case No\"]).tolist()\n",
    "task_list_temp = []\n",
    "for case in case_list:\n",
    "    temp_df = team_report_closed_df[team_report_closed_df[\"Case No\"]==case]\n",
    "    task_list_temp.append(pd.unique(temp_df[\"Task ID\"]).tolist())\n",
    "task_list = [item for sublist in task_list_temp for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalculating the number of days taken - excluding weekends. to be in line with CDM logic, public holidays will not be excluded\n",
    "new_time_taken_temp = []\n",
    "calendar_days_temp = []\n",
    "for task in task_list:\n",
    "    #get list of all dates in \"Task Assigned to Date\" for ONE task, sorted\n",
    "    temp_df = team_report_closed_df[team_report_closed_df[\"Task ID\"]==task]\n",
    "    #create a list of the dates (in chronological order) where tasks are assigned to teams\n",
    "    assigned_dates = pd.to_datetime(temp_df[\"Task Assigned to Date\"]).tolist()\n",
    "    #add task closure date to end of list\n",
    "    closure_date = list(set(pd.to_datetime(temp_df[\"Task Closure Date\"]).tolist()))\n",
    "    assigned_dates.append(closure_date[0])\n",
    "    \n",
    "    #find difference between adjacent dates in the list (1. diff by business days, 2. diff by calendar days)\n",
    "    new_time_taken_temp.append([np.busday_count(j.date(), i.date()) for i,j in zip(assigned_dates[1:], assigned_dates[:-1])])\n",
    "    calendar_days_temp.append([(i.date() - j.date()).days for i,j in zip(assigned_dates[1:], assigned_dates[:-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for new re-calculated time taken that excludes weekends and phs\n",
    "#flatten the temp lists so i can convert them into columns\n",
    "new_time_taken = [item for sublist in new_time_taken_temp for item in sublist]\n",
    "calendar_days = [item for sublist in calendar_days_temp for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8400af",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_report_closed_df[\"New Time Taken\"] = new_time_taken\n",
    "team_report_closed_df[\"Calendar Days\"] = calendar_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bddf23",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfb04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is where- we cross-reference with the user report\n",
    "#flag out the tasks where calendar days ! = time taken aggregate (means that tasks were reassigned out at some point)\n",
    "assigned_out_df = team_report_closed_df[team_report_closed_df[\"Time taken (in days) aggregated\"] != team_report_closed_df[\"Calendar Days\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea796f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare to user report to get the accurate time taken\n",
    "#get list of all the flagged tasks\n",
    "assigned_out_task_list = pd.unique(assigned_out_df[\"Task ID\"]).tolist()\n",
    "#create a new list for storage\n",
    "new_user_time_taken_temp = []\n",
    "\n",
    "#loop through tasks in the flagged task list \n",
    "for task in assigned_out_task_list:\n",
    "    temp_df = team_report_closed_df[team_report_closed_df[\"Task ID\"]==task]\n",
    "    temp_user_df = user_report_df[user_report_df[\"Task ID\"]==task]\n",
    "\n",
    "    #this should create a list of all the dates where the tasks were reassigned + closure date (in chronological order)\n",
    "    assigned_user_dates = pd.to_datetime(temp_user_df[\"Task Assigned to Date\"]).tolist()\n",
    "    closure_date = list(set(pd.to_datetime(temp_df[\"Task Closure Date\"]).tolist()))\n",
    "    assigned_user_dates.append(closure_date[0])\n",
    "    \n",
    "    #find difference between adjacent dates in the list\n",
    "    new_user_time_taken_temp.append([np.busday_count(j.date(), i.date()) for i,j in zip(assigned_user_dates[1:], assigned_user_dates[:-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_time_taken = [item for sublist in new_user_time_taken_temp for item in sublist] #this list is too long. where are the extra values coming from\n",
    "#match back to user report since calculations were made with user report data\n",
    "user_report_df = user_report_df[user_report_df[\"Task ID\"].isin(assigned_out_task_list)]\n",
    "user_report_df[\"Time Taken (User Report)\"] = new_user_time_taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of the total time (.sum()) taken per task per team, based on the user report. store in time_list\n",
    "time_list = []\n",
    "for task, team in zip(assigned_out_df[\"Task ID\"],assigned_out_df[\"Team\"]):\n",
    "    #time taken, in business days, based on user report\n",
    "    x = user_report_df[(user_report_df[\"Task ID\"]==task) & (user_report_df[\"Team\"]==team)][\"Time Taken (User Report)\"].sum()\n",
    "    time_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"New Time Taken\" for flagged tasks are immediately replaced with the Time Taken based on the User Report\n",
    "assigned_out_df[\"New Time Taken\"] = time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge team_report_closed_df and assigned_out_df back together\n",
    "#1. remove the rows from team_report_closed_df that correspond to assigned_out_df\n",
    "#2. append/concat the full assigned_out_df dataframe to team_report_closed_df\n",
    "\n",
    "to_drop = assigned_out_df.index.values.tolist()\n",
    "team_report_closed_df = team_report_closed_df.drop(to_drop)\n",
    "team_report_closed_df = pd.concat([team_report_closed_df, assigned_out_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the part where we take the minimum of the new time taken and the time taken aggregate to account for tasks that were assigned out to Front/IT/etc.\n",
    "team_report_closed_df[\"Min Time Taken\"] = team_report_closed_df[[\"New Time Taken\",\"Time taken (in days) aggregated\"]].min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be01bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a23c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk creation: creating dataframe\n",
    "bulk_creation_df = pd.DataFrame()\n",
    "for idx in range(len(bc_list)):    \n",
    "    temp_df = team_report_closed_df[(team_report_closed_df[\"Team\"]==bc_list[idx][0]) &\n",
    "                                    (team_report_closed_df[\"Process Type\"]==bc_list[idx][1]) &\n",
    "                                    (team_report_closed_df[\"Task Type\"]==bc_list[idx][2])]\n",
    "    bulk_creation_df = pd.concat([bulk_creation_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77433b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk creation: counting volume\n",
    "bc_completed_data = []\n",
    "bc_completed_list = []\n",
    "bc_completed_cases = []\n",
    "bc_rejected_data = []\n",
    "bc_rejected_list = []\n",
    "bc_rejected_cases = []\n",
    "for idx in range(len(process_list)):\n",
    "    \n",
    "    #completed bulk creation tasks\n",
    "    bc_completed_df = bulk_creation_df[(bulk_creation_df[\"Process Type\"]==process_list[idx]) &\n",
    "                                       (bulk_creation_df[\"Currrent Task Status\"]==\"COMPLETED\") &\n",
    "                                       (bulk_creation_df[\"Team\"]==team_list[idx])]\n",
    "    \n",
    "    #sort by case number - this is not for the script, this is for me to visualise better\n",
    "    bc_completed_df = bc_completed_df.sort_values(by=[\"Case No\", \"Task Type\"])\n",
    "\n",
    "    #for each case: volume=max([len(tasks) for each task type]) - for each case: sum # of tasks per task type, then take the maximum\n",
    "    #temp_list = []\n",
    "    temp_dict = {}\n",
    "    for case in list(pd.unique(bc_completed_df[\"Case No\"])): #for each case, get list of unique task types\n",
    "        unique_tasktype_list = list(pd.unique(bc_completed_df[bc_completed_df[\"Case No\"]==case][\"Task Type\"]))\n",
    "        \n",
    "        bc_volume_by_task = []\n",
    "        for tasktype in unique_tasktype_list: #for each task type within case, calculate bulk creation volume: (len(unique(task IDs)))\n",
    "            bc_volume_by_task.append(len(pd.unique(bc_completed_df[(bc_completed_df[\"Case No\"]==case) & (bc_completed_df[\"Task Type\"]==tasktype)][\"Task ID\"])))\n",
    "        \n",
    "        bc_volume_by_case = max(bc_volume_by_task) #bc volume for each case is max(volume of task type 1, volume of task type 2) )\n",
    "        #temp_list.append([case, bc_volume_by_case]) #append to temp_list [(case1, volume), (case2, volume), (case3, volume), etc.]\n",
    "        temp_dict[case] = bc_volume_by_case\n",
    "        \n",
    "    bc_completed_data.append(temp_dict) #append to bc_completed_data [temp_list for Process1TeamA, temp_list for Process2TeamA, etc.]\n",
    "    bc_completed_list.append(list(pd.unique(bc_completed_df[bc_completed_df[\"Team Defined SLA (in days)\"] < bc_completed_df[\"Min Time Taken\"]][\"Case No\"])))\n",
    "    bc_completed_cases.append(list(pd.unique(bc_completed_df[\"Case No\"])))                                                             \n",
    "    \n",
    "    #rejected bulk creation tasks\n",
    "    bc_rejected_df = bulk_creation_df[(bulk_creation_df[\"Process Type\"]==process_list[idx]) &\n",
    "                                      (bulk_creation_df[\"Currrent Task Status\"]==\"REJECTED\") &\n",
    "                                      (bulk_creation_df[\"Team\"]==team_list[idx])]\n",
    "    bc_rejected_df = bc_rejected_df[~bc_rejected_df[\"Task ID\"].isin(bc_completed_df[\"Task ID\"].tolist())] #remove tasks already counted under \"COMPLETED\" so we won't double count\n",
    "    \n",
    "    #sort by case number - this is not for the script, this is for me to visualise better\n",
    "    bc_rejected_df = bc_rejected_df.sort_values(by=[\"Case No\", \"Task Type\"])\n",
    "\n",
    "    #for each case: volume=max([len(tasks) for each task type]) - for each case: sum # of tasks per task type, then take the maximum\n",
    "    #temp_list = []\n",
    "    temp_dict = {}\n",
    "    for case in list(pd.unique(bc_rejected_df[\"Case No\"])): #for each case, get list of unique task types\n",
    "        unique_tasktype_list = list(pd.unique(bc_rejected_df[bc_rejected_df[\"Case No\"]==case][\"Task Type\"]))\n",
    "        \n",
    "        bc_volume_by_task = []\n",
    "        for tasktype in unique_tasktype_list: #for each task type within case, calculate bulk creation volume: (len(unique(task IDs)))\n",
    "            bc_volume_by_task.append(len(pd.unique(bc_rejected_df[(bc_rejected_df[\"Case No\"]==case) & (bc_rejected_df[\"Task Type\"]==tasktype)][\"Task ID\"])))\n",
    "\n",
    "        bc_volume_by_case = max(bc_volume_by_task) #bc volume for each case is max(volume of task type 1, volume of task type 2) )\n",
    "        #temp_list.append([case, bc_volume_by_case]) #append to temp_list [(case1, volume), (case2, volume), (case3, volume), etc.]\n",
    "        temp_dict[case] = bc_volume_by_case\n",
    "            \n",
    "    bc_rejected_data.append(temp_dict) #append to bc_completed_data [temp_list for Process1TeamA, temp_list for Process2TeamA, etc.]\n",
    "    bc_rejected_list.append(list(pd.unique(bc_rejected_df[bc_rejected_df[\"Team Defined SLA (in days)\"] < bc_rejected_df[\"Min Time Taken\"]][\"Case No\"])))\n",
    "    bc_rejected_cases.append(list(pd.unique(bc_rejected_df[\"Case No\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cd643",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86975ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: creating dataframe\n",
    "generic_volume_df = pd.DataFrame()\n",
    "for idx in range(len(gv_list)):\n",
    "    temp_df = team_report_closed_df[(team_report_closed_df[\"Team\"]==gv_list[idx][0]) &\n",
    "                                    (team_report_closed_df[\"Process Type\"]==gv_list[idx][1]) &\n",
    "                                    (team_report_closed_df[\"Task Type\"]==gv_list[idx][2])]\n",
    "    generic_volume_df = pd.concat([generic_volume_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: preprocessing. fill all blank cells, convert each cell to list and take the last element of the list\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].fillna('1')\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].astype(str) #necessary step in the case where all generic volume entries are miraculously somehow all integers\n",
    "generic_volume_df[\"Generic Volume\"] = generic_volume_df[\"Generic Volume\"].apply(lambda x: list(x.split(\",\"))[-1]) #last entry of generic volume is the latest input in CDM task\n",
    "generic_volume_df[\"Generic Volume\"] = (generic_volume_df[\"Generic Volume\"].astype(float)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic volume: counting volume\n",
    "gv_completed_data = []\n",
    "gv_completed_list = []\n",
    "gv_completed_cases = []\n",
    "gv_rejected_data = []\n",
    "gv_rejected_list = []\n",
    "gv_rejected_cases = []\n",
    "for idx in range(len(process_list)):\n",
    "    \n",
    "    #completed generic volume tasks\n",
    "    gv_completed_df = generic_volume_df[(generic_volume_df[\"Process Type\"]==process_list[idx]) &\n",
    "                                        (generic_volume_df[\"Currrent Task Status\"]==\"COMPLETED\") &\n",
    "                                        (generic_volume_df[\"Team\"]==team_list[idx])] \n",
    "    \n",
    "    #sort by case number - this is not for the script, this is for me to visualise better\n",
    "    gv_completed_df = gv_completed_df.sort_values(by=[\"Case No\", \"Task Type\"])\n",
    "    \n",
    "    #temp_list = []\n",
    "    temp_dict = {}\n",
    "    for case in list(pd.unique(gv_completed_df[\"Case No\"])): #for each case\n",
    "        temp_df = gv_completed_df[gv_completed_df[\"Case No\"]==case] #filtered by case ONLY\n",
    "        #counting generic volume by CASE\n",
    "        if temp_df[\"Generic Volume\"].max() == 0: gv_completed_count = 1 \n",
    "        else: gv_completed_count = temp_df[\"Generic Volume\"].max()\n",
    "        #temp_list.append([case, gv_completed_count]) #list of volume by case eg. [[case1,1], [case2,3], [case3,4]]\n",
    "        temp_dict[case] = gv_completed_count\n",
    "        \n",
    "    gv_completed_data.append(temp_dict) #temp_list for each process/team eg. [temp_list of process1teamA, temp_list of process1teamB, etc.]\n",
    "    gv_completed_list.append(list(pd.unique(gv_completed_df[gv_completed_df[\"Team Defined SLA (in days)\"] < gv_completed_df[\"Min Time Taken\"]][\"Case No\"])))\n",
    "    gv_completed_cases.append(list(pd.unique(gv_completed_df[\"Case No\"]))) \n",
    "    \n",
    "    #tests\n",
    "    #print(process_list[idx], team_list[idx], temp_dict.keys())\n",
    "    \n",
    "    #rejected generic volume tasks\n",
    "    gv_rejected_df = generic_volume_df[(generic_volume_df[\"Process Type\"]==process_list[idx]) &\n",
    "                                       (generic_volume_df[\"Currrent Task Status\"]==\"REJECTED\") &\n",
    "                                       (generic_volume_df[\"Team\"]==team_list[idx])]\n",
    "    gv_rejected_df = gv_rejected_df[~gv_rejected_df[\"Case No\"].isin(gv_completed_df[\"Case No\"].tolist())] #remove cases already counted under \"COMPLETED\" so we won't double count\n",
    "\n",
    "    #sort by case number - this is not for the script, this is for me to visualise better\n",
    "    gv_rejected_df = gv_rejected_df.sort_values(by=[\"Case No\", \"Task Type\"])\n",
    "    \n",
    "    #count generic volume by case. if 1 case 1 process type multiple task type with gv, take max gv.\n",
    "    #temp_list = []\n",
    "    temp_dict = {}\n",
    "    for case in list(pd.unique(gv_rejected_df[\"Case No\"])): #for each case with same team and same process type\n",
    "        temp_df = gv_rejected_df[gv_rejected_df[\"Case No\"]==case] #filtered by case ONLY\n",
    "        #counting generic volume by CASE\n",
    "        if temp_df[\"Generic Volume\"].max() == 0: gv_rejected_count = 1 \n",
    "        else: gv_rejected_count = temp_df[\"Generic Volume\"].max()\n",
    "        #temp_list.append([case, gv_rejected_count]) #list of volume by case eg. [[case1,1], [case2,3], [case3,4]]\n",
    "        temp_dict[case] = gv_rejected_count\n",
    "        \n",
    "    gv_rejected_data.append(temp_dict) #temp_list for each process/team eg. [temp_list of process1teamA, temp_list of process1teamB, etc.]\n",
    "    gv_rejected_list.append(list(pd.unique(gv_rejected_df[gv_rejected_df[\"Team Defined SLA (in days)\"] < gv_rejected_df[\"Min Time Taken\"]][\"Case No\"])))\n",
    "    gv_rejected_cases.append(list(pd.unique(gv_rejected_df[\"Case No\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7f2dc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case volume: creating remaining dataframe\n",
    "case_volume_df = team_report_closed_df.drop(generic_volume_df.index, errors='ignore')\n",
    "case_volume_df = case_volume_df.drop(bulk_creation_df.index, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just mark which cases are past SLA and which arent\n",
    "case_volume_df['Overdue Days'] = case_volume_df[\"Team Defined SLA (in days)\"] - case_volume_df[\"Min Time Taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_volume_df.to_excel('case_volume_sla.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c28bcd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#case volume: counting volume\n",
    "case_completed_data = []\n",
    "case_completed_list = []\n",
    "case_completed_cases = []\n",
    "case_rejected_data = []\n",
    "case_rejected_list = []\n",
    "case_rejected_cases = []\n",
    "for idx in range(len(process_list)):\n",
    "    #completed cases\n",
    "    case_completed_df = case_volume_df[(case_volume_df[\"Process Type\"]==process_list[idx]) &\n",
    "                                       (case_volume_df[\"Currrent Task Status\"]==\"COMPLETED\") &\n",
    "                                       (case_volume_df[\"Team\"]==team_list[idx])]\n",
    "    \n",
    "    completed_case_list = list(pd.unique(case_completed_df[\"Case No\"]))\n",
    "    #list compre makes a list of [[case1,1],[case2,1],etc.]. case vol is always 1.\n",
    "    #case_completed_data.append([[case_list[i],1] for i in range(len(completed_case_list))]) \n",
    "    case_completed_data.append({completed_case_list[completed_case_list.index(i)]:1 for i in completed_case_list})\n",
    "    case_completed_list.append(list(pd.unique(case_completed_df[case_completed_df[\"Team Defined SLA (in days)\"] < case_completed_df[\"Min Time Taken\"]][\"Case No\"])))\n",
    "    case_completed_cases.append(list(pd.unique(case_completed_df[\"Case No\"])))\n",
    "    \n",
    "    #rejected cases\n",
    "    case_rejected_df = case_volume_df[(case_volume_df[\"Process Type\"]==process_list[idx]) &\n",
    "                                      (case_volume_df[\"Currrent Task Status\"]==\"REJECTED\") &\n",
    "                                      (case_volume_df[\"Team\"]==team_list[idx])]\n",
    "    case_rejected_df = case_rejected_df[~case_rejected_df[\"Case No\"].isin(case_completed_df[\"Case No\"].tolist())] #remove cases already counted under \"COMPLETED\" so we won't double count\n",
    "    \n",
    "    rejected_case_list = list(pd.unique(case_rejected_df[\"Case No\"]))\n",
    "    #list compre makes a list of [[case1,1],[case2,1],etc.]. case vol is always 1.\n",
    "    #case_rejected_data.append([[case_list[i],1] for i in range(len(rejected_case_list))]) \n",
    "    case_rejected_data.append({rejected_case_list[rejected_case_list.index(i)]:1 for i in rejected_case_list})\n",
    "    case_rejected_list.append(list(pd.unique(case_rejected_df[case_rejected_df[\"Team Defined SLA (in days)\"] < case_rejected_df[\"Min Time Taken\"]][\"Case No\"])))\n",
    "    case_rejected_cases.append(list(pd.unique(case_rejected_df[\"Case No\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fb15e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total volume for bulk creation, generic volume, case volume - do not sum! take max volume for EACH CASE\n",
    "#step 1: create set of all the cases for 1 Team/Process combo\n",
    "#step 2: get all volume values that correspond to each case in the set\n",
    "#step 3: find max of all the values, sum all the maxs <<-- this is the final volume for 1 process/team\n",
    "\n",
    "#completed cases\n",
    "completed_data = []\n",
    "for i in range(len(bc_completed_data)): #to loop through the list. each list is the same length, bc_completed pick arbitrarily\n",
    "    case_list = list(bc_completed_data[i].keys()) + list(gv_completed_data[i].keys()) + list(case_completed_data[i].keys())\n",
    "    case_set = set(case_list)\n",
    "    x = 0\n",
    "    for j in case_set:\n",
    "        templist = [bc_completed_data[i].get(j), gv_completed_data[i].get(j), case_completed_data[i].get(j)]\n",
    "        temparray = np.array(templist, dtype=np.float64)\n",
    "        x += np.nanmax(temparray)\n",
    "    completed_data.append(x)\n",
    "\n",
    "#rejected cases\n",
    "rejected_data = []\n",
    "for i in range(len(bc_rejected_data)): #to loop through the list. each list is the same length, bc_completed pick arbitrarily\n",
    "    case_list = list(bc_rejected_data[i].keys()) + list(gv_rejected_data[i].keys()) + list(case_rejected_data[i].keys())\n",
    "    case_set = set(case_list)\n",
    "    x = 0\n",
    "    for j in case_set:\n",
    "        templist = [bc_rejected_data[i].get(j), gv_rejected_data[i].get(j), case_rejected_data[i].get(j)]\n",
    "        temparray = np.array(templist, dtype=np.float64)\n",
    "        x += np.nanmax(temparray)\n",
    "    rejected_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed cases\n",
    "completed_cases = [\", \".join(set(i+j+k)) for i,j,k in zip(bc_completed_cases, gv_completed_cases, case_completed_cases)]\n",
    "completed_list = [\", \".join(set(i+j+k)) for i,j,k in zip(bc_completed_list, gv_completed_list, case_completed_list)]\n",
    "\n",
    "#rejected cases\n",
    "rejected_cases = [\", \".join(set(i+j+k)) for i,j,k in zip(bc_rejected_cases, gv_rejected_cases, case_rejected_cases)]\n",
    "rejected_list = [\", \".join(set(i+j+k)) for i,j,k in zip(bc_rejected_list, gv_rejected_list, case_rejected_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81f1ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f413300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median turnaround time\n",
    "medianTAT_data = []\n",
    "for idx in range(len(process_list)):\n",
    "    #data for calculating median per processtype/team\n",
    "    medianTAT_df = team_report_closed_df[(team_report_closed_df[\"Process Type\"]==process_list[idx]) &\n",
    "                                         (team_report_closed_df[\"Currrent Task Status\"]!=\"CANCELLED\") &\n",
    "                                         (team_report_closed_df[\"Team\"]==team_list[idx])]    \n",
    "    #for case in pd.unique(medianTAT_df[\"Case No\"]):\n",
    "        #medianTAT_df[\"Min Time Taken\"] = medianTAT_df[medianTAT_df[\"Case No\"]==case][\"Min Time Taken\"].max()\n",
    "    #medianTAT_df = medianTAT_df.drop_duplicates(subset=\"Case No\") #take only first instance of each case\n",
    "    #medianTAT_data.append(medianTAT_df[\"Min Time Taken\"].median()) #finally calculate median\n",
    "    \n",
    "    df = medianTAT_df.groupby(by='Case No')[['Min Time Taken']].max().reset_index()\n",
    "    medianTAT_data.append(df['Min Time Taken'].median())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcb02c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zip(process_list,team_list,completed_data,rejected_data,medianTAT_data,completed_list,rejected_list,completed_cases,rejected_cases)\n",
    "output_df = pd.DataFrame(data, columns=[\"Process Type\",\n",
    "                                        \"Team\",\n",
    "                                        \"Total Volume (Completed)\",\n",
    "                                        \"Total Volume (Rejected)\",\n",
    "                                        \"Median TAT (in days)\",\n",
    "                                        \"Completed Cases Exceeding SLA\",\n",
    "                                        \"Rejected Cases Exceeding SLA\",\n",
    "                                        \"All Completed Cases\",\n",
    "                                        \"All Rejected Cases\"])\n",
    "output_df = output_df.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d2fc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_df.to_csv(\"../Output/CompletedRejectedCases_1.csv\", index=False)\n",
    "print(\"Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
